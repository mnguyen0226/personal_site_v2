[{"content":"[v.1.0] (09/15/2023): Post started!\nForeword The Rubber-Duck method\nWhat do you think the problem is? What exactly do you want to happen? What is actually happening? How did you get there? What have you tried so far? HTML, CSS, \u0026amp; Flexbox JavaScript Citation Cited as:\nFull-stack Web Development: The Odin Project. https://mnguyen0226.github.io/posts/web_dev_odin/post/. Or\n@article{nguyen2023odin, title = \u0026#34;Full-stack Web Development: The Odin Project\u0026#34;, author = \u0026#34;Nguyen, Minh\u0026#34;, journal = \u0026#34;mnguyen0226.github.io\u0026#34;, year = \u0026#34;2023\u0026#34;, month = \u0026#34;September\u0026#34;, url = \u0026#34;https://mnguyen0226.github.io/posts/web_dev_odin/post/\u0026#34; } References [1] Full Stack JavaScript | The Odin Project. Theodinproject.com. Published 2023. Accessed October 25, 2023. https://www.theodinproject.com/paths/full-stack-javascript ‚Äå\n‚Äå[2] Trautman E. Why Learning to Code is So Damn Hard | Thinkful. Thinkful. Published April 20, 2018. Accessed October 25, 2023. https://www.thinkful.com/blog/why-learning-to-code-is-so-damn-hard/ ‚Äå\n[3] Florian. How to Use Google to Solve Your Programming Questions ‚Äì Coding in Flow. Codinginflow.com. Published March 5, 2018. Accessed October 25, 2023. https://old.codinginflow.com/google-programming-questions ‚Äå\nFig. 2: Golden Gate Bridge, San Francisco, U.S.A (Image Source: Maarten van den Heuvel @ Unsplash). ","permalink":"https://mnguyen0226.github.io/posts/web_dev_odin/post/","summary":"[v.1.0] (09/15/2023): Post started!\nForeword The Rubber-Duck method\nWhat do you think the problem is? What exactly do you want to happen? What is actually happening? How did you get there? What have you tried so far? HTML, CSS, \u0026amp; Flexbox JavaScript Citation Cited as:\nFull-stack Web Development: The Odin Project. https://mnguyen0226.github.io/posts/web_dev_odin/post/. Or\n@article{nguyen2023odin, title = \u0026#34;Full-stack Web Development: The Odin Project\u0026#34;, author = \u0026#34;Nguyen, Minh\u0026#34;, journal = \u0026#34;mnguyen0226.github.io\u0026#34;, year = \u0026#34;2023\u0026#34;, month = \u0026#34;September\u0026#34;, url = \u0026#34;https://mnguyen0226.","title":"Full-stack Web Development: The Odin Project"},{"content":"[v.1.0] (08/21/2023): Post started!\nThe field of cybersecurity consists of: measures of deter, prevent, detect, and correct security violations that involve the storage, processing, and transmission of information.\nComputer Security Objectives: CIA Confidentiality:\nData confidentiality: assures that private or confidential information is not made available or disclosed to unauthorized individuals. Privacy: assures that individuals control or influence what information related to them may be collected and stored and by whom and to whom that information may be disclosed. Ex: Student grad information is an assert whose confidentiality is considered to be highly important by students. Integrity:\nData integrity: assures that information and programs are changed only in a specified and authorized manner. System integrity: assures that a system performs its intended function in an unpaired manner, free from deliberate or inadvertent unauthorized manipulation of the system. Ex: Patient information stored in the database - inaccurate info could result in serious harm or death to a patient and expose the hospital to massive liability. Availability: assures that the systems work promptly and service is not denied to authorized users.\nEx: An online telephone directory lookup application would be classified as a low-availability requirement. Fig. 1: CIA Triad. Privacy is not security, but security is necessary to achieve privacy (it is not sufficient).\nAuthencity: verifying that users are who they say they are and that each input arriving at the system cam from a trusted source.\nAccountability: the security goal that generates that requirement for actions of an entity to be traced uniquely to that entity.\nThe OSI Security Architecture Security attack: any action that compromised the security of information owned by an organization.\nSecurity mechanism: a process (or a device incorporating such a process) that is designed to detect, prevent, or recover from a security attack.\nSecurity service: a process or communication service that enhances the security of the data processing systems and the information transfers of an organization. Intended to counter security attacks and they make use of one or more security mechanism to provide the service.\nSecurity Attacks Threat: a potential for violation of security, which exists when there is a circumstance, capability, action, or event that could breach security and cause harm. That is, a threat is a possible danger that might exploit a vulnerability.\nAttack: an assault on system security that derives from an intelligent threat; that is, an intelligent act that is deliberate attempt (especially in the sense of a method or technique) to evade security services and violate the security policy of a system.\nPassive attack: attempts to learn or make use of info from the system but does not affect system resources, such as monitoring and eavesdrop. There are 2 types:\nThe release of message contents. Traffic analysis Active attack: attempts to alter system resources or affect their operation, such as modify, abuse resources. There are 4 types:\nMasquerade: Takes place when one entity pretends to be a different entity. Usually includes one of the other forms of active attack. Replay: Involves the passive capture of a data unit and its subsequent retransmission to produce an unauthorized effect. Modification of messages: Some portion of a legitimate message is altered, or messages are delayed or reordered to produce an unauthorized effect. Denial of service: Prevents or inhibits the normal use or management of communications facilities. Security Services Authentication: concerned with assuring that a communication is authentic.\nAccess control: is the ability to limit and control the access to the host system and the applicaiton via communication links. To achieve this, each entity trying to gain access must first be identified, or authenticated, so that access rights can be tailored to the individual.\nData Confidentiality: is both the protection of transmitted data from passive attacks or the protection of traffic flow from analysis.\nData Integrity: is a connectionless integrity service deals with individual messages without regard to any larger context or generally provides protection against message modification only. I don\u0026rsquo;t care if you know the info but I do care if you modify it.\nNonrepudiation: prevents either sender or receiver from denying a transmitted message. When a message is sent, the receiver can prove that the alleged sender in fact send the message. When a message is received, the sender can prove that the alleged receiver in fact received the message.\nAvalability of services: addresses the security concerns raised by denial-of-service attacks.\nSecurity Mechanisms Cryptographic algorithms: we can distinguish between reversible cryptographic mechanisms and irreversible cryptographic mechanisms.\nData integrity: covers a variety of mechanisms used to assure the integrity of a data unit or stream of data units.\nDigital signature: data appended to, or a cryptographic transformation of, a data unit that allows a recipient of the data unit to prove the source and integrity of data unit and protect against forgery.\nAuthentication exchange: a mechanism intended to ensure the identity of an entity by means of information exchange.\nAccess control: a variety of mechanisms that enforce access rights to resources.\nTraffic padding: the insertion of bits into gaps in a data stream to frustrate traffic analysis attempts.\nRouting control: enables selections of particular physically or logically ensure routes for certain data.\nNotarization: the use of a trusted third party to assure certain properties of a data exchange.\nCryptography Crytographic algorithms and protocols can be grouped into 4 main areas:\nSymmetric encryption: used to conceal the contents of blokcs or streams of data of any size, including messages, files, encryption keys, and passwords. Asymmetric encryption: used to conceal small blocks of data, such as encryptionn keys and hash function values, which are used in digital signatures. Data integrity algorithms: used to protect blocks of data, such as messages, from alteration. Authentication protocols: schemes based on the used of cryptographic algorithms designed to authenticate the identity of entities. Fig. 2: Types of cryptographic algorithms. Keyless algorithms: a pseudorandom number generator produces a deterministic sequence of numbers or bits that has the appearance of being a truly random sequence.\nSingle-key algorithms: depends on the use of a secret key.\nAsymmetric (two keys) algorithms: a pair of keys are used instead of only one shared secret key.\nFundametals of Security Design Principles Economy of mechanism: the design of security measures embodied in both hardware and software should be as simple and small as possible.\nFail-safe default: access decisions should be based on permission rather than exclusion - the default situation is lack of access, and the protection scheme identifies conditions under which access is permitted.\nComplete mediation: every access much be checked against the access control mechanism.\nOpen design: the design of a security mechanism should be open rather than secret.\nSeparation of priviledge: a practice in which multiple privilege attributes are required to achieve access to restricted resource.\nLeast privilege: every process and every user of the system should operate using the least set of privileges necessary to perform the task.\nLeast common mechanism: the design should minimize the functions shared by different users, providing mutual security.\nPsychological acceptability: security mechanisms should not interfere unduly with the work of users, while at the same time metting the needs of those who authorize access.\nIsolation: a principle that applies in 3 contexts\nPublic access systems should be isolated from critical resources to prevent disclosure to tampering. The processes and files of individual users should be isolated from one another except where it is explicitly desired. Security mechanisms should be isolated in the sense of preventing access to those mechanisms. Encapsulation: viewed as a specific form of isolation based on object-oriented functionality.\nModularity: refers both to the development of security functions as separate, protected modules and to the use of modular architecture for mechanism design and implementation.\nLayering: referes to the use of multiple, overlapping protection approaches addressing the people, technology, and operational aspects of the information systems.\nLeast astonishment: a program or user interface should always respond in the way that least likely to astonish the user.\nAttack surface Network attack surface: vulnerabilities over an enterprise network, wide-area network, or internet.\nSoftware attack surface: vulnerabilities in application, utility, or OS code.\nHuman attack surface: vulnerabilities created by personnel or outsiders such as social engineering, human error, and trusted insiders.\nFig. 3: Defense in depth and attack surface. Citation Cited as:\nInformation and Network Security Concepts https://mnguyen0226.github.io/posts/info_security/post/ Or\n@article{nguyen2023insc, title = \u0026#34;Information and Network Security Concepts\u0026#34;, author = \u0026#34;Nguyen, Minh\u0026#34;, journal = \u0026#34;mnguyen0226.github.io\u0026#34;, year = \u0026#34;2023\u0026#34;, month = \u0026#34;August\u0026#34;, url = \u0026#34;https://mnguyen0226.github.io/posts/info_security_1/post/\u0026#34; } References [1] Pearson, https://www.pearson.com/en-us/subject-catalog/p/Stallings-Pearson-e-Text-for-Cryptography-and-Network-Security-Principles-and-Practice-Access-Card-8th-Edition/P200000003477 (accessed Aug. 21, 2023).\nFig. 4: Lone Eagle Peak, Colorado, U.S.A (Image Source: Alyssa Teboda @ Unsplash). ","permalink":"https://mnguyen0226.github.io/posts/info_security_1/post/","summary":"[v.1.0] (08/21/2023): Post started!\nThe field of cybersecurity consists of: measures of deter, prevent, detect, and correct security violations that involve the storage, processing, and transmission of information.\nComputer Security Objectives: CIA Confidentiality:\nData confidentiality: assures that private or confidential information is not made available or disclosed to unauthorized individuals. Privacy: assures that individuals control or influence what information related to them may be collected and stored and by whom and to whom that information may be disclosed.","title":"Information and Network Security Concepts"},{"content":"[v.1.1] (08/15/2023): Source code published!\n[v.1.0] (05/27/2023): Post published!\nRecently, I had an opportunity of joining the Mathbridge project, led by Virginia Tech\u0026rsquo;s Computer Science Department. Our goal was to develop a data visualization web application that serves as an interactive playground for students to explore and visualize concepts related to linear algebra and machine learning algorithms. This project holds particular significance for my university, which has a strong focus on machine learning and regularly produces groundbreaking research in the field. By creating this website, we aim to attract students and provide them with a valuable resource for their ML-focused programs. I\u0026rsquo;m delighted to announce that we have successfully deployed the prototype of the website, and we are continuously working on adding additional stylings, ML algorithms, and expanding the tech stack to enhance the user experience. Stay tuned for regular updates as we evolve and improve this exciting project.\nStarter code can be found here.\nFig. 1: Only after document, test, and code review are completed that a feature-implementation task is considered completed (Image source: MonkeyUser.com). Architecture The web application we have developed follows the single-page application (SPA) architecture, allowing for real-time updates and seamless user interactions. While there are popular SPA frameworks like Vue.js (open-sourced by Evan You), React (open-sourced by Meta), and Angular (open-sourced by Google), for this project, I made the decision to use Dash, a Python framework specifically designed for creating analytical web applications.\nDash combines the best of both worlds, incorporating elements of React and Flask API. It leverages Flask\u0026rsquo;s backend infrastructure to handle HTTP requests and responses while providing responsive components that enable dynamic interactions with the user.\nNow, why did I choose Dash? My introduction to this powerful tool came through the CS-5764: Information Visualization class, where I learned about its capabilities. Additionally, Dash offers a strong integration with Plotly, a widely-used visualization library (often seen on platforms like Kaggle), which allows for the creation of interactive plots. The reactive nature of Dash simplifies development by automatically updating visualizations when data or inputs change, similar to web-hooks.\nFig. 2: Architecture of Mathbridge. Let's dive into the front-end and back-end aspects of the application: Front-end To build the interactive visualizations, I utilized Dash Core Components (DCC), which provides a way to define HTML layouts in Dash, styled with CSS. As the project progresses, I plan to gradually integrate Dash Bootstrap Components (DBC) to further enhance the styling and overall user experience.\nBack-end Dash\u0026rsquo;s powerful callbacks are a key component of the back-end infrastructure. These callbacks connect user input to the appropriate functions and facilitate real-time updates of visualizations, calculated values, or any other types of output. To handle data manipulation and analysis, I leveraged popular data science libraries such as NumPy and Pandas. It\u0026rsquo;s worth noting that, at present, there is no database integration in this project.\nBy leveraging Dash\u0026rsquo;s reactive components and powerful callbacks, we have created an intuitive and interactive web application for visualizing linear algebra and machine learning concepts. The combination of Dash\u0026rsquo;s front-end capabilities and Flask\u0026rsquo;s backend infrastructure, along with the seamless integration with Plotly, has made development efficient and enjoyable.\nDeployment To ensure consistent performance across different environments, I utilized Docker for containerization. Docker effectively addresses the issue of \u0026ldquo;it works on my machine but not on yours.\u0026rdquo; By using Docker, I created containers that provide isolated and reproducible environments for my application. The Dockerfile served as the blueprint for building a Docker image, and the Docker container acted as the runtime instance of that image.\nTo make the deployment process more convenient, I pushed the built and tested Docker image to Docker Hub. Docker Hub serves as a centralized registry where the image can be easily accessed. This streamlined the deployment process, allowing for effortless deployment on various machines and environments without the need for manual image transfers or sharing through other means.\nFig. 3: Always check whether the product is deployed, else no update will be made (Image source: MonkeyUser.com). Why did I switch from using DockerHub to GitLab? I encountered rate limits on Docker Hub and had concerns about the security of my pushed images. As a solution, I switched to using GitLab Container Registry. GitLab Container Registry, integrated within my GitLab projects, provides a secure and scalable alternative for storing and managing Docker images. This shift allowed me to overcome rate limiting restrictions and gain more control over the security and accessibility of my Docker images. I could now push the Docker images to GitLab Container Registry and subsequently pull them from there for deployment on my target environments.\nFor scalable deployment and management, I turned to Kubernetes, a powerful container orchestration platform. By leveraging Kubernetes, I could effectively manage and scale my web application based on demand. With features like pods and load balancing, Kubernetes enabled the website to achieve high availability and efficient resource utilization. To deploy the website, I utilized Virginia Tech\u0026rsquo;s cloud service. Both the Kubernetes web interface and the KubeCTL command line tool were employed for managing the deployment, ensuring flexibility and ease of use.\nThrough the utilization of Docker for containerization, GitLab Container Registry for image storage and management, and Kubernetes for scalable deployment, I have established a robust and efficient deployment process for the web application. This combination of technologies allows for seamless and reliable deployment across different environments while ensuring optimal performance and security.\nIn conclusion, our data visualization web application built using Dash has laid the foundation for an exciting and interactive learning platform for students and enthusiasts of linear algebra and machine learning. The project\u0026rsquo;s journey has been filled with learning opportunities and significant milestones, and we are committed to further enhancing the application as it evolves.\nFig. 4: Project development is an iterative process, until the requirements are met and satisfied üòÜ (Image source: MonkeyUser.com). One aspect we will focus on is improving the user interface and overall user experience. By gradually incorporating DBC, we aim to create a visually appealing and intuitive interface that enhances user engagement and interaction. The addition of styling elements will contribute to a more polished and professional look, making the application even more inviting for users. Furthermore, we plan to introduce more advanced ML algorithms to the application. By leveraging the power of popular data science libraries such as NumPy and Pandas, we can integrate cutting-edge algorithms that enable users to explore and experiment with various machine learning techniques. This expansion will provide students with a hands-on experience in applying ML concepts and foster a deeper understanding of the subject matter.\nCitation Cited as:\nNguyen, Minh. (May 2023). Building a Data Visualization Web App with Dash https://mnguyen0226.github.io/posts/mathbridge/post/ Or\n@article{nguyen2023webdash, title = \u0026#34;Building a Data Visualization Web App with Dash\u0026#34;, author = \u0026#34;Nguyen, Minh\u0026#34;, journal = \u0026#34;mnguyen0226.github.io\u0026#34;, year = \u0026#34;2023\u0026#34;, month = \u0026#34;May\u0026#34;, url = \u0026#34;https://mnguyen0226.github.io/posts/mathbridge/post/\u0026#34; } References [1] ‚ÄúGitlab documentation,‚Äù GitLab Documentation, https://docs.gitlab.com/ (accessed May 26, 2023).\n[2] ‚ÄúCommand line tool (kubectl),‚Äù Kubernetes, https://kubernetes.io/docs/reference/kubectl/ (accessed May 26, 2023). [3] ‚ÄúKubernetes Documentation,‚Äù Kubernetes, https://kubernetes.io/docs/home/ (accessed May 26, 2023).\n[4] ‚ÄúDocker docs: How to build, share, and run applications,‚Äù Docker Documentation, https://docs.docker.com/ (accessed May 26, 2023).\n[5] ‚ÄúDash documentation \u0026amp; user guide,‚Äù Plotly, https://dash.plotly.com/ (accessed May 26, 2023).\nFig. 5: Golden Bridge in Da Nang, Viet Nam (Image source: Jet Dela Cruz @ Unsplash). ","permalink":"https://mnguyen0226.github.io/posts/mathbridge/post/","summary":"[v.1.1] (08/15/2023): Source code published!\n[v.1.0] (05/27/2023): Post published!\nRecently, I had an opportunity of joining the Mathbridge project, led by Virginia Tech\u0026rsquo;s Computer Science Department. Our goal was to develop a data visualization web application that serves as an interactive playground for students to explore and visualize concepts related to linear algebra and machine learning algorithms. This project holds particular significance for my university, which has a strong focus on machine learning and regularly produces groundbreaking research in the field.","title":"Building a Data Visualization Web App with Dash"},{"content":"[v.1.0] (06/15/2023): Post published!\nDuring a recent interview for a software engineer intern position, I had an intriguing conversation with a start-up CEO. We discussed a software-system problem that presented an opportunity to gradually integrate a machine learning (ML) solution. The challenge involved a Software-as-a-Service (SaaS) platform that aimed to match buyers or customers with suitable sellers or agents. This blog chronicles my research into the fascinating profile-matching problem, with a specific focus on the matching algorithms employed.\nSimilar matching services can be observed in popular dating apps like Tinder and Bumble, as well as social media platforms such as LinkedIn, Facebook, Instagram, and YouTube.\nFig. 1: Harnessing the power of technology to connect people (Image source: freeCodeCamp). In this blog I will introduce four potential ML-based solutions:\nAgent-Profile Recommendation. Similar Agent-Profile Listing. People You Might Know. Chatbot. Prerequisites Before diving into the profile-matching solutions, it\u0026rsquo;s important to establish that the following two features have already been implemented or will be addressed separately:\nBuyer-profile creation:\nAccount Creation: Buyers must be able to create an account by providing necessary credentials. Details on filing personal information will be discussed in later sections focusing on profile-matching algorithms. Robust Authentications: Implementing a secure authentication system, including features like 2-factor authentication (2FA), is crucial to maintain the integrity of buyer accounts. Communication Preferences: Buyers should have the option to specify their preferred communication channels and indicate their availability for booking meetings or engaging in chats with sellers. Seller-profile creation:\nAccount Creation: Sellers should have the capability to create an account using appropriate credentials. Details on filing personal information will be discussed in later sections focusing on profile-matching algorithms. Robust Authentications: Similar to buyers, incorporating robust authentication measures such as 2-factor authentication (2FA) helps ensure the security and trustworthiness of seller accounts. Availability and Profile Updates: Sellers should be able to manage their availability status and make necessary updates to their profiles or listed commodities. Agent-Profile Recommendation Consider the task of matching buyers and sellers as a recommendation system, where the goal is to pair each buyer with the most suitable potential seller (or vice versa).\nFig. 2: Diagram illustrating Agent-Profile recommendation system. Assumptions: Initially, the buyer may not need to directly interact with the seller, but they should have access to view the seller\u0026rsquo;s profile and schedule a conversation or chat if desired. It is also assumed that the buyer has logged in, allowing us to collect data from them. Furthermore, it is important to have a substantial number of sellers\u0026rsquo; profiles available in our database.\nFraming problem as ML task: The objective is to maximize the number of relevant sellers within certain constraints, such as identifying the top 5 relevant sellers. The definition of relevance can be established by engineers or managers based on predefined rules. For instance, a seller\u0026rsquo;s profile can be considered relevant if the buyer explicitly marks it as a favorite by pressing a \u0026ldquo;star\u0026rdquo; button. Once relevance is defined, we can construct a dataset and train a model to predict the relevance score between buyers and seller(s).\nData Collection: Since both sellers and buyers need to log in, there are two approaches to collecting personal information and preference data: filtering-tabs or questionnaires. These questions can be curated by the company\u0026rsquo;s commodity specialists. Here are examples of databases for sellers, buyers, and their interactions.\nFig. 3: Illustration of Buyer, Seller, and Buyer-Seller Interaction databases. Matching Algorithms: Within the realm of agent-profile recommendation, there are three types of algorithms commonly employed: Rule-based Filtering (non-personalized), Profile-based Filtering (personalized), and Collaborative Filtering (personalized).\nRule-based Filtering Rule-based filtering is a non-personalized approach that does not require the application of ML. In this method, the sellers\u0026rsquo; profiles are filtered based on the buyer\u0026rsquo;s selected filtering tabs or questionnaire responses. This approach relies solely on the Seller database and can serve as a good starting point for our system.\n‚úÖ Pros:\nMinimal data requirement. ‚ñ™ Rule-based filtering operates efficiently with the existing seller database without the need for extensive data collection or model training. ‚ùå Cons:\nLack of personalization. ‚ñ™ Generic rules used in rule-based filtering may result in recommendations that are not highly tailored to the individual preferences of buyers. Profile-based Filtering Profile-based filtering is a personalized algorithm that utilizes the features of sellers\u0026rsquo; profiles to recommend new seller profiles to buyers based on their previous interactions and preferences.\nFig. 4: Illustration of Profile-based Filtering algorithm diagram. For example, in Fig. 4, we observe that Buyer 1 has engaged with Seller 1, Seller 2, and Seller 3 in the past, indicating relevance through actions such as starring the profile, engaging in conversations, providing feedback, or making purchases. Since Seller 4 has a similar profile to Seller 1, Seller 2, and Seller 3, the system will recommend Seller 4 to Buyer 1.\n‚úÖ Pros:\nRecommendations of newly added seller profiles. ‚ñ™ Profile-based filtering can effectively recommend newly added seller profiles to buyers, ensuring timely exposure to relevant sellers without prior viewing. ‚ùå Cons:\nChallenges in discovering new buyer interests. ‚ñ™ Profile-based filtering may struggle to identify a buyer's new interests that have not been previously exhibited. It relies on historical engagement data, which may overlook emerging preferences. Collaborative Filtering Collaborative filtering is a filtering solution that leverages the similarities between buyers to recommend new buyers\u0026rsquo; profiles. The underlying idea is that buyers who exhibit similar behavior or preferences are likely to be interested in similar sellers.\nFig. 5: Illustration of Collaborative Filtering algorithm diagram. For instance, in Fig. 5, the objective is to recommend a new seller\u0026rsquo;s profile to Buyer 2. To achieve this, we first identify a similar buyer to Buyer 2 based on their previous interactions, such as Buyer 1. Next, we identify a seller\u0026rsquo;s profile, in this case, Seller 3, which Buyer 1 has engaged with but Buyer 2 has not yet seen. We then recommend Seller 3 to Buyer 2.\nThe main difference between collaborative filtering and profile-based filtering is that collaborative filtering does not rely on the features of sellers\u0026rsquo; profiles. Instead, it exclusively relies on the historical interactions of buyers to make recommendations.\n‚úÖ Pros:\nNo domain knowledge required. ‚ñ™ Collaborative filtering does not rely on sellers' profiles, resulting in lower computational requirements and reducing the need for extensive domain knowledge. ‚ùå Cons:\nAccuracy issues with few seller profiles. ‚ñ™ In the case of a limited number of seller profiles, the system may struggle to provide accurate recommendations, known as the cold-start problem . Inability to handle niche interests. ‚ñ™ Collaborative filtering, based on similar buyers, may have difficulty accommodating niche interests with limited data, potentially overlooking unique preferences. Fig. 6: Comparison table of Profile-based Filtering and Collaborative Filtering. Similar Agent-Profile Listing In our SaaS platform, we can incorporate a feature that presents a list of \u0026ldquo;similar sellers\u0026rsquo; profiles\u0026rdquo; to the buyer after they have clicked on a specific seller\u0026rsquo;s profile.\nFig. 7: Illustration of Similar Agent-Profile Listing algorithm diagram. Assumptions: The input for this feature is the list of sellers\u0026rsquo; profiles that the buyer is currently viewing, which can be obtained through manual filtering or selection via clicks. The desired output is a ranked list of similar listings that the buyer is likely to click on next. This system can cater to both logged-in (identified) and non-logged-in (anonymous) buyers.\nFraming problem as ML task: We observe that the sequence of listings that a buyer clicks on often shares common characteristics, such as sellers located in the same city or offering similar commodities within an acceptable price range. Leveraging this observation, we define the ML objective as accurately predicting the list of sellers\u0026rsquo; profiles that the buyer is likely to click on next.\nData Collection: For logged-in users, personal information and preference data can be collected through filtering-tabs or questionnaires. These data collection methods can be curated by the company\u0026rsquo;s commodity specialists. In the case of anonymous users, we can utilize the ELK (ElasticSearch, Kibana, Logstash) stack and the Mozilla Interaction Observer API to capture users\u0026rsquo; engagement with the web app. This stack has been utilized by companies like Facebook and Netflix for their algorithms, analyzing user scroll feed and recommending content based on scroll activity. Software companies like Amplitude offer similar services through their Amplitude APIs, enabling developers to create data analytic dashboards that showcase users\u0026rsquo; web app engagement levels. Here are examples of seller, buyer, and interaction databases that can be utilized for data analysis and model training.\nFig. 8: Examples of Buyer, Seller, and Buyer-Seller Interaction databases. Matching Algorithm: Rather than relying solely on the buyer\u0026rsquo;s historical interactions to understand their long-term interests, our approach for profile recommendations focuses on the buyer\u0026rsquo;s recently viewed listings. This approach is known as a session-based recommendation system. The objective is to predict the next profile that the buyer is likely to click on, based on the sequence of sellers\u0026rsquo; profiles they have recently browsed. By prioritizing the user\u0026rsquo;s most recent interactions, we aim to provide more accurate and timely recommendations, tailored to their immediate preferences.\nFig. 9: KNN for Similar Seller Profile Listing algorithm. To implement this system, we train a model that maps each listing to an embedding vector. By doing so, if two listings frequently appear together in the buyer\u0026rsquo;s browsing history, their corresponding embedding vectors will be positioned closely in the embedding space. This proximity indicates a higher likelihood of similarity between the listings.\nWhen recommending similar listings, our system searches the embedding space for listings that are closest to the ones currently being viewed. In Fig. 9, we illustrate this process by selecting the top 3 listings with the closest embeddings. One simple supervised learning algorithm that can be used for this task is the K-Nearest Neighbor (KNN) algorithm.\n‚úÖ Pros:\nTimely recommendations. ‚ñ™ The algorithm focuses on the buyer's recent interactions, providing recommendations that align with their immediate preferences and increasing relevance and timeliness. Personalization. ‚ñ™ By considering the buyer's browsing history, the algorithm generates personalized recommendations tailored to their preferences, enhancing the user experience. Embedding space efficiency. ‚ñ™ Mapping listings to embedding vectors enables faster computation and retrieval of similar listings, improving system performance. ‚ùå Cons:\nLimited long-term preferences. ‚ñ™ The algorithm may not fully capture the buyer's long-term interests or evolving preferences, potentially leading to less accurate recommendations over time. Cold-start problem. ‚ñ™ New buyers or sellers with limited browsing history pose challenges for accurate recommendations due to insufficient data to establish patterns or similarities. Dependency on browsing history. ‚ñ™ Sparse or incomplete browsing history may compromise the algorithm's performance and result in less accurate suggestions. People You Might Know This system is particularly useful when buyers are unsure of what they want but are interested in using the service. Its purpose is to connect individuals who share common interests and help them find mutually beneficial deals. Known as \u0026ldquo;People You May Know\u0026rdquo; (PYMK), it provides a list of users who you may want to connect with based on shared attributes such as location, personality traits, or commodity preferences. Major social platforms like Facebook, LinkedIn, and Twitter leverage the power of PYMK to enhance their software.\nFig. 10: Illustration of PYMK algorithm diagram. Assumptions: In the context of matching suitable sellers to buyers (or vice versa), we assume that there is a single commodity being handled by multiple sellers.\nFraming problem as ML task: The primary objective is to maximize the number of strong connections between users. This entails identifying individuals who have compatible preferences and characteristics, increasing the likelihood of a successful match.\nData Collection: To collect personal information and preference data, both sellers and buyers are required to log in. This data can be gathered through filtering-tabs or questionnaires, which can be curated by the company\u0026rsquo;s commodity specialists. Additionally, companies may employ tools such as the Myers-Briggs Type Indicator (MBTI) to assess personality preferences and the Gallup Clifton Strengths assessment to understand individuals\u0026rsquo; strengths or natural talents. The idea behind these assessments is that individuals with similar personality traits and complementary strengths are more likely to form meaningful connections. Here are examples of seller, buyer, and seller-buyer rating databases that can be utilized for data analysis and model training.\nFig. 11: Examples of Buyer, Seller, and Buyer-Seller Rating databases. Matching Algorithms: In the PYMK system, there are two approaches that can be used: Pointwise Learning to Rank and Edge Prediction.\nPointwise Learning to Rank In the Pointwise Learning to Rank (LTR) approach, we utilize a binary classification model that takes two user profiles as input and outputs the probabilities of connection strength between them.\nFig. 12: Illustration of LTR algorithm diagram. ‚úÖ Pros:\nSimplicity. ‚ñ™ LTR offers a straightforward binary classification model for assessing connection strength between users based on their profiles. Privacy preservation. ‚ñ™ LTR's pairwise comparisons protect user privacy by not exposing detailed profiles. Efficient computation. ‚ñ™ LTR's binary classification model is computationally efficient, making it suitable for large-scale systems. ‚ùå Cons:\nLimited context. ‚ñ™ LTR may overlook the broader social context and interactions among users, potentially resulting in less accurate predictions. It doesn't capture network effects and community dynamics that influence connections. Edge Prediction The Edge Prediction approach is commonly used in social media platforms as it encourages users to build larger networks. As we are not trying to build a social network, this approach might not be suitable for our SaaS. In this approach, we enhance the model by incorporating graph information. This allows the model to leverage additional knowledge extracted from the social graph to predict the existence of an edge (connection) between two nodes (users). It\u0026rsquo;s important to note that the graph represents the relationships or edges between nodes, capturing the connections between users in the system.\n‚úÖ Pros:\nSocial context. ‚ñ™ Edge Prediction leverages graph information to consider social connections, enhancing the accuracy of recommendations by capturing network effects and community dynamics. Enhanced recommendations. ‚ñ™ Edge Prediction provides more personalized and meaningful recommendations, leading to stronger connections and user satisfaction. Scalability. ‚ñ™ Edge Prediction scales well for large-scale social graphs, allowing for efficient processing. ‚ùå Cons:\nIncreased complexity. ‚ñ™ Integrating graph information adds complexity, requiring additional computational resources and algorithmic considerations. Data sparsity. ‚ñ™ Edge Prediction may struggle with sparse data or limited connections, leading to less accurate predictions for users with fewer network connections. Chatbot Slow customer support is a common challenge that can be addressed effectively through the integration of chatbots. These automated systems can reduce manual labor while providing quick assistance to meet buyer\u0026rsquo;s needs.\nFig. 13: Chatbot (Image source: Siam Computing). Assumptions: Although slow customer support is not inherently an ML problem, optimizing the response time lies in routing buyer requests to the appropriate seller. This can be framed as a multi-class classification problem, where the objective is to classify and route requests accurately.\nFraming problem as ML task: Slow customer support is a problem but it is not an ML problem as there is no obvious objective function to optimize. The bottleneck here is the responding to buyer\u0026rsquo;s requests lies in routing the request to the right seller. Thus, this is a multi-class classification problem.\nData Collection: Data can be collected through filtering-tabs or chatbot questionnaires, leveraging the interaction between buyers and the chatbot. Advanced pretrained natural language processing (NLP) models can be used to extract relevant features from the customer conversations.\nMatching Algorithm: To address the routing challenge, a combination of NLP techniques, text processing, and feature extraction can be employed. For multi-class classification, lightweight algorithms like Decision Trees can be utilized. Alternatively, deep learning models such as pretrained BERT can be employed for more complex conversation and text classification tasks.\n‚úÖ Pros:\nEnhanced customer support. ‚ñ™ Chatbots provide quick and automated assistance, improving the overall customer support experience. Reduced manual labor. ‚ñ™ Chatbots reduce the need for manual communication, freeing up resources for other tasks. Data-driven personalization. ‚ñ™ Chatbots collect and analyze data to offer personalized recommendations and responses. Advanced NLP capabilities. ‚ñ™ Pretrained NLP models enable accurate feature extraction and understanding of customer conversations. ‚ùå Cons:\nLack of human interaction. ‚ñ™ Some buyers may prefer the human touch and empathy that chatbots may lack. Limited contextual understanding. ‚ñ™ Complex or nuanced customer requests may pose challenges for chatbots in understanding and providing appropriate responses. Initial development and training effort. ‚ñ™ Building and training chatbot systems, especially with advanced models, requires significant upfront investment. Potential misinterpretation of intent. ‚ñ™ Chatbots may occasionally misinterpret buyer queries, leading to incorrect responses or routing to inappropriate sellers. Citation Cited as:\nNguyen, Minh. (May 2023). Machine Learning for Profile-Matching System https://mnguyen0226.github.io/posts/profile_matching/post/ Or\n@article{nguyen2023mlpm, title = \u0026#34;Machine Learning for Profile-Matching System\u0026#34;, author = \u0026#34;Nguyen, Minh\u0026#34;, journal = \u0026#34;mnguyen0226.github.io\u0026#34;, year = \u0026#34;2023\u0026#34;, month = \u0026#34;May\u0026#34;, url = \u0026#34;https://mnguyen0226.github.io/posts/profile_matching/post/\u0026#34; } References [1] C. Huyen, Designing Machine Learning Systems. Beijing: O‚ÄôReilly, 2022.\n[2] Amplitude, ‚ÄúAmplitude apis,‚Äù Amplitude Developer Center, https://www.docs.developers.amplitude.com/analytics/apis/ (accessed May 28, 2023).\n[3] MozDevNet, ‚ÄúIntersection observer API - web apis: MDN,‚Äù Web APIs | MDN, https://developer.mozilla.org/en-US/docs/Web/API/Intersection_Observer_API (accessed May 28, 2023).\n[4] ‚ÄúThe Elk Stack: From the creators of Elasticsearch,‚Äù Elastic, https://www.elastic.co/what-is/elk-stack (accessed May 28, 2023).\n[5] ‚ÄúOptimizing people you may know (PYMK) for Equity in Network Creation,‚Äù LinkedIn Engineering, https://engineering.linkedin.com/blog/2021/optimizing-pymk-for-equity-in-network-creation (accessed May 28, 2023).\n[6] ‚ÄúServing a billion personalized news feeds,‚Äù YouTube, https://youtu.be/Xpx5RYNTQvg?t=1823 (accessed May 28, 2023).\n[7] M. Grbovic, ‚ÄúListing embeddings in search ranking,‚Äù Medium, https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e (accessed May 28, 2023).\n[8] ‚ÄúPowered by AI: Instagram‚Äôs explore recommender system,‚Äù Meta AI, https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system (accessed May 28, 2023).\n[9] Deep Neural Networks for YouTube recommendations, https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf (accessed May 28, 2023).\n[10] C. Goodrow, ‚ÄúOn YouTube‚Äôs recommendation system,‚Äù blog.youtube, https://blog.youtube/inside-youtube/on-youtubes-recommendation-system/ (accessed May 28, 2023).\nFig. 14: Early morning mist at Ha Long Bay, Vietnam (Image source: Warren @ Unsplash). ","permalink":"https://mnguyen0226.github.io/posts/profile_matching/post/","summary":"[v.1.0] (06/15/2023): Post published!\nDuring a recent interview for a software engineer intern position, I had an intriguing conversation with a start-up CEO. We discussed a software-system problem that presented an opportunity to gradually integrate a machine learning (ML) solution. The challenge involved a Software-as-a-Service (SaaS) platform that aimed to match buyers or customers with suitable sellers or agents. This blog chronicles my research into the fascinating profile-matching problem, with a specific focus on the matching algorithms employed.","title":"Machine Learning for Profile-Matching System"},{"content":"[v.1.0] (05/08/2023): Post published!\nChip Huyen, a Vietnamese writer, computer scientist, and co-founder of Claypot AI, has an impressive background as a lecturer at Stanford and as a machine learning engineer at NVIDIA, Snorkel AI, Netflix, and Primer. I have been an avid reader of Chip\u0026rsquo;s books since her best-selling works in Vietnam, which inspired me to pursue my study-abroad journey in the U.S. Her latest book, published in June 2022, offers invaluable insights and practical advice on building reliable machine learning systems. After reading it for the first time, I was captivated by the depth of knowledge shared, prompting me to revisit the book multiple times to fully absorb its ideas. In this blog post, I will share my reflections and takeaways from Chip Huyen\u0026rsquo;s book after the first-read, which has greatly influenced my understanding and approach to machine learning.\nFig. 1: Designing Machine Learning Systems's cover (Image source: O'Reilly). Overview of ML Systems In her book, Chip Huyen presents an overview of ML systems, defining eight main components that constitute such systems. The book adopts a \u0026ldquo;divide-and-conquer\u0026rdquo; approach, examining each component individually to facilitate a comprehensive understanding of the entire system.\nFig. 2: Diagram illustrating the components of a machine learning system (Image inspired from: O'Reilly). Chip\u0026rsquo;s definition of machine learning revolves around learning complex patterns from existing data and using them to make predictions on unseen data. This definition aligns with the prevalent use of supervised learning, as most ML applications involve leveraging vast amounts of user data stored in SQL databases.\nSo why does company integrate ML in their product? Companies integrate ML into their products due to the low cost of wrong predictions, scalability advantages, and the ability of ML models to adapt to changing patterns. For example, by identifying potential customers, displaying targeted ads, and offering timely discounts, companies like Lyft can significantly increase profits by reducing costs and attracting more long-term users.\nSo what is the difference between traditional software vs. ML? There are notable differences between traditional software engineering (SWE) and ML systems. In SWE, the emphasis is on modular and separated components, whereas in ML systems, code and data intertwine, making it challenging to apply SWE principles such as S.O.L.I.D or the 12-factor app to these systems.\nFig. 3: Comparison between Software Engineering and Machine Learning (Image inspired from: O'Reilly). Considerations Before applying ML algorithms to solve a problem, it is essential to frame the problem in a way that ML can address it effectively. This involves determining the appropriate task for ML, such as binary classification, multi-class classification, or regression.\nWhile ML metrics like accuracy or F1 score are important, most companies prioritize the ultimate goal of any project: increasing profit. This can be achieved by boosting sales, reducing costs, enhancing customer satisfaction, or increasing app engagement.\nFig. 4: Alignment of Integration in Software Engineering and Machine Learning with business objectives (Image source: MonkeyUser.com). Predicting ad click-through rates and fraud detection are popular ML use cases because they directly impact business metrics. Higher click-through rates translate into increased ad revenue, while detecting and preventing fraudulent transactions saves money.\nData \u0026amp; Feature Engineering Let\u0026rsquo;s look at how data can be handled in the data science perspective. For now, I will focus on sampling, labeling, and feature engineering techniques.\nData Sampling To create train/validate/test sets, there are various data sampling techniques available. Two common approaches include random sampling and stratified sampling.\nData Labeling When it comes to data labeling, there are several options to consider:\nHand-labeling: This approach can be expensive, time-consuming, and may raise concerns about data privacy. Third-party service: Companies like Scale AI offer data labeling services and have recently secured significant contracts, such as the $250 million data labeling contract from the Department of Defense. Benchmark datasets: Utilizing established benchmark datasets like ImageNet and BATADAL can provide pre-labeled data for specific tasks. Methodological changes: If feasible, it's possible to switch from traditional supervised learning with training from scratch to alternative approaches like transfer learning, self-supervised learning, or semi-supervised learning. These methods can reduce the reliance on extensive labeled data. Fig. 5: Importance of dataset selection and processing for targeted application (Image source: MonkeyUser.com). Feature Engineering The significance of feature engineering cannot be overstated in the development of ML models. Even with state-of-the-art ML architectures, performance can suffer if an inadequate set of features is used. While (deep learning) models can extract features to some extent, providing well-engineered features that enable the model to better comprehend the data can greatly benefit your application. By inputting carefully selected and curated features, you enhance the model\u0026rsquo;s ability to effectively capture and utilize relevant information.\nML Algorithms \u0026amp; Evaluation Let\u0026rsquo;s see what is Chip\u0026rsquo;s tips in terms of suitable ML algorithm(s), training paradigm, and evaluation metrics.\nModel Selection Given the constraints of limited computation power and time, it is crucial to strategically choose ML models based on their advantages and disadvantages. This is where the knowledge gained from classes and academic papers becomes applicable. Benchmark datasets, such as ImageNet, SMAC, or VQA, can serve as valuable references for model selection. Additionally, factors like the number of parameters (model complexity) and interpretability can influence the choice of models. The availability of auto-selecting tools like AutoML from H2O.ai or AutoTrain from HuggingFace provides reasonable options as well.\nDistributed Training Paradigms Consideration of distributed training paradigms is important when dealing with large models or datasets. Let\u0026rsquo;s examine data parallelism and model parallelism.\nData parallelism involves splitting the data across multiple machines, training the model on each machine, and accumulating gradients.\nModel parallelism, on the other hand, involves training different components of the model on different machines. For instance, machine 0 handles the computation for the first two layers while machine 1 handles the next two layers. It\u0026rsquo;s important to note that \u0026ldquo;model parallelism\u0026rdquo; can be misleading because in some cases, parallel execution doesn\u0026rsquo;t occur across different parts of the model on different machines. Instead, each part is executed sequentially or consecutively.\nFig. 6: Comparison of Data Parallelism and Model Parallelism (Image source: anyscale.com). Model Evaluation Deploying a model involves more than simply pickling the model and using it in a Python script. There are several important aspects to consider in the deployment process.\nModel Deployment Model deployment is not simply \u0026ldquo;pickle\u0026rdquo; the model and use it on a Python script, there are several aspects to be considered.\nBatch vs. Online Training Online prediction is when predictions are generated and returned as soon as requests for these predictions arrive. For example, you enter an English sentence into Google Translate and get back its French translation immediately. When doing online prediction, requests are sent to the prediction service via RESTful APIs, that means to send back the input data, call model prediction and return the prediction result\nBatch prediction is when predictions are generated periodically or whenever triggered. The predictions are stored somewhere, such as in SQL tables or an in-memory database, and retrieved as needed. For example, Netflix might generate movie recommendations for all of its users every four hours, and the precomputed recommendations are fetched and shown to users when they log on to Netflix. For example, every 4 hours, Netflix might generate movie recommendations for all of its users.\nModel Compression In scenarios where convolutional neural networks are used, model compression techniques can be applied. For example, replacing the convolutional layer with depth-wise separable convolutional layers can significantly reduce the number of parameters while maintaining performance. Similarly, classical ML algorithms like Decision Trees can be pruned to reduce model complexity.\nCloud vs. Hardware Model deployment options include cloud deployment to platforms like AWS or GCP and hardware deployment, often referred to as edge computing. Cloud deployment offers scalability but comes with associated costs ranging from $50K to $2M per year. On the other hand, hardware deployment enables models to operate in environments with limited or unreliable internet connectivity, such as rural areas or developing countries. Edge computing also reduces network latency concerns. However, privacy risks still exist, as attackers could potentially steal user data by physically accessing the devices. Major companies like Google, Apple, and Tesla are actively developing their own chips optimized for edge computing.\nFig. 7: Google's Pixel 6 Tensor Chip, Apple's M1 Chip, Tesla's D1 Chip. In support of the semiconductor industry, the CHIPS and Science Act was signed by President Biden on August 9, 2022, aiming to strengthen the US semiconductor supply chain and foster research and development of advanced technologies within the country.\nInfrastructure The right infrastructure setup can automate processes, saving engineering time, accelerating ML application development and delivery, reducing the risk of bugs, and enabling new use cases. Conversely, a poorly implemented infrastructure can be cumbersome and costly to replace.\nFig. 8: Machine learning infrastructure layers for building reliable systems. Storage: is where data is collected and stored. It can range from simple setups like hard disk drives (HDD) or solid-state drives (SSD) to more sophisticated solutions like centralized storage in platforms such as Amazon S3 or Snowflake. Data can be stored in a single location or distributed across multiple locations.\nResource Management: comprises tools to schedule and orchestrate your workloads to make the most out of your available compute resources. Popular examples in this category include Airflow, Kubeflow, and Metaflow, which help manage and allocate computing resources efficiently.\nML Platform: provides tools to aid the development of ML applications such as model stores, feature stores, and monitoring tools. Prominent examples of ML platforms include SageMaker and MLflow, which provide comprehensive capabilities for ML application development and management.\nDeployment: Major cloud providers like AWS (SageMaker), GCP (Vertex AI), Azure (Azure ML), and Alibaba (Machine Learning) offer robust deployment options for ML applications. These platforms provide infrastructure and services to streamline the deployment process and ensure scalability and reliability.\nDevelopment Environment: A variety of development environments are available to facilitate ML application development. Tools such as VS Code, PyCharm, Anaconda, Jupyter Notebook, Git, and Docker are commonly used by data scientists and developers to write and manage code, create reproducible environments, and collaborate efficiently.\nTeam Structures In many job descriptions, it is common to see Data Scientists taking ownership of the entire process, from data collection to productionization. However, Netflix has implemented an effective team structure for full-stack data scientists.\nNetflix\u0026rsquo;s model involves specialists who initially own specific parts of a project. These specialists create tools and automation to streamline their respective areas. Data scientists can then leverage these tools to take ownership of their projects from end to end. As tools are developed and integrated with each other, the entire workflow is cohesive and well-integrated.\nThis team structure at Netflix allows for a seamless collaboration where specialists contribute their expertise to build tools, and data scientists can utilize these tools to manage the complete life cycle of their projects.\nFig. 9: Netflix's full cycle data science development with specialists create reusable tools. (Image source: Netflix Technology Blog). Citation Cited as:\nNguyen, Minh. (May 2023). Designing Machine Learning Systems: A Summary https://mnguyen0226.github.io/posts/ml_systems_design/post/ Or\n@article{nguyen2023mlsys, title = \u0026#34;Designing Machine Learning Systems: A Summary\u0026#34;, author = \u0026#34;Nguyen, Minh\u0026#34;, journal = \u0026#34;mnguyen0226.github.io\u0026#34;, year = \u0026#34;2023\u0026#34;, month = \u0026#34;May\u0026#34;, url = \u0026#34;https://mnguyen0226.github.io/posts/ml_systems_design/post/\u0026#34; } References [1] ‚ÄúFull cycle developers at Netflix,‚Äù Medium, https://netflixtechblog.com/full-cycle-developers-at-netflix-a08c31f83249 (accessed May 19, 2023).\n[2] ‚ÄúPresident Biden Signs Chips and science act into law,‚Äù White \u0026amp; Case LLP, https://www.whitecase.com/insight-alert/president-biden-signs-chips-and-science-act-law (accessed May 19, 2023).\n[3] ‚ÄúCloud cost management and optimization by ANODOT,‚Äù Anodot, https://www.anodot.com/cloud-cost-management/ (accessed May 19, 2023).\n[4] F. Chollet, ‚ÄúXception: Deep learning with depthwise separable convolutions,‚Äù arXiv.org, https://arxiv.org/abs/1610.02357 (accessed May 19, 2023).\n[5] C. Huyen, ‚ÄúIntroduction to streaming for Data scientists,‚Äù Chip Huyen, https://huyenchip.com/2022/08/03/stream-processing-for-data-scientists.html#:~:text=Batch%20prediction%20means%20periodically%20generating,whenever%20they%20visit%20the%20website. (accessed May 19, 2023).\n[6] Y. Wu et al., ‚ÄúGoogle‚Äôs Neural Machine Translation System: Bridging the gap between human and machine translation,‚Äù arXiv.org, https://arxiv.org/abs/1609.08144 (accessed May 19, 2023).\n[7] ‚ÄúWhat is distributed training?,‚Äù Anyscale, https://www.anyscale.com/blog/what-is-distributed-training (accessed May 19, 2023).\n[8] VQA: Visual question answering | IEEE conference publication - IEEE xplore, https://ieeexplore.ieee.org/document/7410636 (accessed May 19, 2023).\n[9] B. Ellis et al., ‚ÄúSMACv2: An improved benchmark for cooperative multi-agent reinforcement learning,‚Äù arXiv.org, https://arxiv.org/abs/2212.07489 (accessed May 19, 2023).\n[10] Practical lessons from predicting clicks on ads at facebook, https://quinonero.net/Publications/predicting-clicks-facebook.pdf (accessed May 19, 2023).\n[11] ‚ÄúScale AI selected by U.S. Department of Defense to accelerate government‚Äôs AI capabilities,‚Äù Business Wire, https://www.businesswire.com/news/home/20220131005304/en/Scale-AI-Selected-by-U.S.-Department-of-Defense-to-Accelerate-Government%E2%80%99s-AI-Capabilities (accessed May 19, 2023).\n[12] ‚ÄúDeep learning with python,‚Äù Manning Publications, https://www.manning.com/books/deep-learning-with-python (accessed May 19, 2023).\n[13] J. Henriksen, ‚ÄúValuing lyft requires a deep look into unit economics,‚Äù Forbes, https://www.forbes.com/sites/jeffhenriksen/2019/05/17/valuing-lyft-requires-a-deep-look-into-unit-economics/?sh=17155c9a7add (accessed May 19, 2023).\n[14] L. Ceci and J. 7, ‚ÄúMobile app user acquisition cost 2019,‚Äù Statista, https://www.statista.com/statistics/185736/mobile-app-average-user-acquisition-cost/ (accessed May 19, 2023).\n[15] C. Huyen, ‚ÄúDesigning machine learning systems,‚Äù O‚ÄôReilly Online Learning, https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/ (accessed May 19, 2023).\nFig. 10: Morning hike at McAfee Knob, Roanoke, Virginia, U.S.A. ","permalink":"https://mnguyen0226.github.io/posts/ml_systems_design/post/","summary":"[v.1.0] (05/08/2023): Post published!\nChip Huyen, a Vietnamese writer, computer scientist, and co-founder of Claypot AI, has an impressive background as a lecturer at Stanford and as a machine learning engineer at NVIDIA, Snorkel AI, Netflix, and Primer. I have been an avid reader of Chip\u0026rsquo;s books since her best-selling works in Vietnam, which inspired me to pursue my study-abroad journey in the U.S. Her latest book, published in June 2022, offers invaluable insights and practical advice on building reliable machine learning systems.","title":"Designing Machine Learning Systems: A Summary"},{"content":"[v.1.0] (04/28/2023): Post published!\nI recently finished an excellent graduate course, Software Engineering (CS5704), and learned about different aspects of software projects and how different-size companies handle their technical/business changes to deliver successful products to their customer. Some important topics are Process Models (Waterfall, V-Model, Spiral, Agile), Requirements Definition, and Architecture Design Patterns. Especially, S.O.L.I.D principles have struck me as must-known concepts for writing better and cleaner code.\nWhy do S.O.L.I.D principles matter? According to Uncle Bob, bad code slows down the development team as it is confusing and fragile. Confusing code does not explain what it is doing, while fragile code breaks in many places when you change one or a few lines of code.\nWhat we want is the code that is clear, rigid, and reusable.\nFun Fact: In his talk in S.O.L.I.D Principles, he mentioned that he was not the first to realize or coin the acronym \u0026ldquo;SOLID.‚Äù\nSingle Responsibility Principle SRP: \u0026ldquo;A class should have one, and only one reason to change\u0026rdquo; ‚Äî Robert C. Martin. In Object Oriented Programming (OOP), a class should have only one primary function. If there is more than one utility for that class, we should split it into multiple courses. This helps distribute the functional responsibilities across numerous classes or objects (or developers).\nFig. 1: Divide and conquer! Distribute responsibilities to avoid code and project overload (Image source: MonkeyUser.com). Web Development Example Let\u0026rsquo;s say you are a developer in the Google Shopping team who is in charge of designing a class to process post-item-purchase.\nCode Example class PostPurchaseProcess: def web_notification(self, message): \u0026#34;\u0026#34;\u0026#34; Code to send confirmation bill to Google Chrome \u0026#34;\u0026#34;\u0026#34; pass def email_notification(self, message): \u0026#34;\u0026#34;\u0026#34; Code to send confirmation bill to Gmail \u0026#34;\u0026#34;\u0026#34; pass def phone_notification(self, message): \u0026#34;\u0026#34;\u0026#34; Code to send confirmation bill to Google Pixel \u0026#34;\u0026#34;\u0026#34; pass In the example above, the class PostPurchaseProcess violates the SRP as it contains too many responsibilities: sending notifications to web app, email, and mobile. What if there are errors in sending notifications to Google Pixel and Gmail? It may take time to pinpoint precisely which function(s) is responsible for the mistake!\nFix: We can refactor the code into multiple classes, each with single responsibility.\nFig. 2: Design refactored with the Single Responsibility Principle for improved clarity and maintainability. Code Example class WebPurchaseProcess: def web_notification(self, message): \u0026#34;\u0026#34;\u0026#34; Code to send confirmation bill to Google Chrome \u0026#34;\u0026#34;\u0026#34; pass class EmailPurchaseProcess: def email_notification(self, message): \u0026#34;\u0026#34;\u0026#34; Code to send confirmation bill to Gmail \u0026#34;\u0026#34;\u0026#34; pass class PhonePurchaseProcess: def phone_notification(self, message): \u0026#34;\u0026#34;\u0026#34; Code to send confirmation bill to Google Pixel \u0026#34;\u0026#34;\u0026#34; pass Data Science Example Suppose you are a Data Scientist at C3.ai who is processing a tabular dataset for a supervised classification application. There are multiple steps to investigate the structure, quality, and content of the dataset, such as: checking datatypes, removing duplicates, data imputation, removing outliers, class-balancing, feature analysis, or feature engineering. Similar to the Google Shopping example above, to follow the SRP, we will need to put these steps into their separate class.\nCode Example class DataImputation: def median_fill(self, data): \u0026#34;\u0026#34;\u0026#34; Code to fill missing data by median of feature \u0026#34;\u0026#34;\u0026#34; pass class OutlierRemoval: def remove_by_euclidean_dist(self, data): \u0026#34;\u0026#34;\u0026#34; Code to remove outliers using Euclidean distance \u0026#34;\u0026#34;\u0026#34; pass class FeatureAnalysis: def pearson_corr_cal(self, data): \u0026#34;\u0026#34;\u0026#34; Code to calculate Pearson correlation scores between input feature(s) and output label(s) \u0026#34;\u0026#34;\u0026#34; pass However, I don\u0026rsquo;t find this principle helpful in a Kaggle or data science project, as each Jupyter Notebook cell can be run and tested individually.\nOpen-Closed Principle OCP: \u0026ldquo;A module (or component) should be open for extension but closed for modification\u0026rdquo; ‚Äî Bertrand Meyer. When making changes, the principle prevents the already functional design from bugs or breaks. This principle promotes a modular and flexible design that allows for the easy integration of a new idea while making your codebase more maintainable and scalable. The OCP can be hard to understand, so let\u0026rsquo;s walk through some examples.\nFig. 3: The challenge of implementing new features without refactoring existing code (Image source: MonkeyUser.com). Web Development Example An easy-to-see symptom of OCP violation to look for is the use of if/elif/else or switch-case statements. Let\u0026rsquo;s say that you are a (Flask or Django) backend developer at Meta who is writing a REST API that uses HTTP request protocols (POST, GET, PUT, DELETE) to allow users to interact with the database via CRUD (Create, Read, Update, Delete).\nCode Example class RequestHandler: def handle_request(self, request): \u0026#34;\u0026#34;\u0026#34; Code to handle request based on type \u0026#34;\u0026#34;\u0026#34; if request.method == \u0026#34;GET\u0026#34;: self.handle_get(request) elif request.method == \u0026#34;POST\u0026#34;: self.handle_post(request) elif request.method == \u0026#34;PUT\u0026#34;: self.handle_put(request) elif request.method == \u0026#34;DELETE\u0026#34;: self.handle_delete(request) def handle_get(self, request): \u0026#34;\u0026#34;\u0026#34; Code to handle GET request \u0026#34;\u0026#34;\u0026#34; pass def handle_post(self, request): \u0026#34;\u0026#34;\u0026#34; Code to handle POST request \u0026#34;\u0026#34;\u0026#34; pass def handle_put(self, request): \u0026#34;\u0026#34;\u0026#34; Code to handle PUT request \u0026#34;\u0026#34;\u0026#34; pass def handle_delete(self, request): \u0026#34;\u0026#34;\u0026#34; Code to handle DELETE request \u0026#34;\u0026#34;\u0026#34; pass The example above violates OCP because every time a new request type is added (e.g., PATCH), our RequestHandler class needs to be modified. This can introduce new bugs into existing code. As the OCP stated, we should design our code to be fixed but extended.\nFix: A solution to OCP violation is to separate each request type into individual classes, thus abstracting the RequestHandler class. Therefore, if we want to add a PATCH request, we can extend our API by adding a new PatchRequestHander class.\nFig. 4: Refactored design showcasing the application of the Open-Closed Principle. Code Example class RequestHandler: def handle_request(self, request): \u0026#34;\u0026#34;\u0026#34; Code to handle request based on type \u0026#34;\u0026#34;\u0026#34; request.handle() class GetRequestHandler: def handle(self): \u0026#34;\u0026#34;\u0026#34; Code to handle GET request \u0026#34;\u0026#34;\u0026#34; pass class PostRequestHandler: def handle(self): \u0026#34;\u0026#34;\u0026#34; Code to handle POST request \u0026#34;\u0026#34;\u0026#34; pass class PutRequestHandler: def handle(self): \u0026#34;\u0026#34;\u0026#34; Code to handle PUT request \u0026#34;\u0026#34;\u0026#34; pass class DeleteRequestHandler: def handle(self): \u0026#34;\u0026#34;\u0026#34; Code to handle DELETE request \u0026#34;\u0026#34;\u0026#34; pass class PatchRequestHandler: def handle(self): \u0026#34;\u0026#34;\u0026#34; Code to handle PATCH request (extended) \u0026#34;\u0026#34;\u0026#34; pass Data Science Example Let\u0026rsquo;s say you are a Machine Learning Engineer at NVIDIA who is writing a Python script for a baseline model with data preprocessing, model training, and model evaluation. Like the REST API example above, you want your class ModelPipeline to remain closed for modification but open for extension by strictly following the OCP.\nCode Example class DataPreprocessor: def preprocess(self, dataset): \u0026#34;\u0026#34;\u0026#34; Code to preprocess data \u0026#34;\u0026#34;\u0026#34; pass class ModelTrainer: def train(self, dataset): \u0026#34;\u0026#34;\u0026#34; Code to train model \u0026#34;\u0026#34;\u0026#34; pass class ModelEvaluator: def evaluate(self, model, dataset): \u0026#34;\u0026#34;\u0026#34; Code to evaluate model \u0026#34;\u0026#34;\u0026#34; pass class ModelPipeline: def __init__(self, preprocessor, trainer, evaluator): \u0026#34;\u0026#34;\u0026#34; Code to build a ModelPipeline constructor (object) \u0026#34;\u0026#34;\u0026#34; self.preprocessor = preprocessor self.trainer = trainer self.evaluator = evaluator def run_pipeline(self, dataset): \u0026#34;\u0026#34;\u0026#34; Code to run the machine learning project end-to-end \u0026#34;\u0026#34;\u0026#34; preprocessed_data = self.preprocessor.preprocess(dataset) model = self.trainer.train(preprocessed_data) evaluation_result = self.evaluator.evaluate(model, preprocessed_data) return evaluation_result Your teammate develops a new way of processing the dataset. Luckily, due to your guideline of OCP, your teammate can easily extend the existing baseline model by inheriting the DataPreprocessor class without the risk of breaking your functional baseline design.\nCode Example class NewDataPreprocessor(DataPreprocessor): def preprocess(self, dataset): \u0026#34;\u0026#34;\u0026#34; Code to preprocess data with new technique \u0026#34;\u0026#34;\u0026#34; pass Liskov Substitution Principle LSP: \u0026ldquo;Subclasses should be substitutable for their base classes (without affecting the correctness of the program)\u0026rdquo; ‚Äî Barbara Liskov. In OOP, what we want is for any method or code that works for a base class should continue to work correctly when used with the derived types. This principle ensures the inheritance hierarchies are consistent, extensible, and correct.\nFig. 5: Creating a predictable and reusable codebase design (Image source: MonkeyUser.com). Web Development \u0026amp; Data Science Example Let\u0026rsquo;s say that you are to design a codebase at Netflix to write processed data into a MySQL database and a CSV file (You can think of adding new columns into a database by scraping or engineering new features).\nCode Example class DataHandler(): def write_db(self, data): \u0026#34;\u0026#34;\u0026#34; Code to write processed data to MySQL database \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Handling MySQL database.\u0026#34;) def write_csv(self, data): \u0026#34;\u0026#34;\u0026#34; Code to write processed data to CSV file \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Handling CSV file.\u0026#34;) class WriteDB(DataHandler): def write_db(self, data): \u0026#34;\u0026#34;\u0026#34; Code to write processed data to MySQL database \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Handling MySQL database.\u0026#34;) def write_csv(self, data): \u0026#34;\u0026#34;\u0026#34; Code to write processed data to CSV file \u0026#34;\u0026#34;\u0026#34; raise Exception(\u0026#34;Error: Can\u0026#39;t write to CSV file.\u0026#34;) class WriteCSV(DataHandler): def write_db(self, data): \u0026#34;\u0026#34;\u0026#34; Code to write processed data to MySQL database \u0026#34;\u0026#34;\u0026#34; raise Exception(\u0026#34;Error: Can\u0026#39;t write to MySQL database.\u0026#34;) def write_csv(self, data): \u0026#34;\u0026#34;\u0026#34; Code to write processed data to CSV file \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Handling CSV file.\u0026#34;) Here, our base class DataHandler defined two methods, write_db() and write_csv(). The derived class WriteDB inherits from DataHander and overrides the write_csv method. However, instead of providing the expected behavior, it prints an error message indicating it can\u0026rsquo;t write to a CSV file. Similarly, the derived class WriteCSV prints out the error message indicating it can\u0026rsquo;t write to MySQL file. This design violates the LSP as the derived classes do not behave as expected based on the contract defined by the DataHandler base class. The base class is designed to be too specific, thus causing its children to handle edge case(s) based on the characteristics of the child classes.\nFixed: Let\u0026rsquo;s write a more generic base class!\nFig. 6: Codebase design refactored with Liskov Substitution Principle. Code Example class DataHandler(): def write(self, data): \u0026#34;\u0026#34;\u0026#34; Code to handle processed data \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Handling data.\u0026#34;) class WriteDB(DataHandler): def write(self, data): \u0026#34;\u0026#34;\u0026#34; Code to write processed data to MySQL database \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Handling MySQL database.\u0026#34;) class WriteCSV(DataHandler): def write(self, data): \u0026#34;\u0026#34;\u0026#34; Code to write processed data to CSV file \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Handling CSV file.\u0026#34;) If you have an object of type WriteDB or WriteCSV, you can safely use it wherever an object of type DataHandler is expected because they adhere to the same contract.\nInterface Segregation Principle ISP: \u0026ldquo;Many client-specific interfaces are better than one general purpose interface\u0026rdquo; ‚Äî Robert C. Martin. If we have an extensive interface with many functions, the class implementing the interface might only use some defined functions! It is better to break up the interface into multiple smaller interfaces; then, we can inherit our class\u0026rsquo;s needed interface(s). This principle promotes code modularity, reduces unnecessary dependencies, and makes it easier to maintain/extend the existing codebase.\nFig. 7: Challenges of dealing with extensive classes for refactoring, inheritance, and reusability (Image source: MonkeyUser.com). Web Development Example Let\u0026rsquo;s say you are a Full-stack Web Developer at Odoo who writes a simple web app with a home page and admin page.\nCode Example class WebPage: def render(self): \u0026#34;\u0026#34;\u0026#34; Code to render HTML of a generic web page \u0026#34;\u0026#34;\u0026#34; pass def save(self): \u0026#34;\u0026#34;\u0026#34; Code to save data of a generic web page into a database \u0026#34;\u0026#34;\u0026#34; pass def delete(self): \u0026#34;\u0026#34;\u0026#34; Code to delete data of a generic web page from a database \u0026#34;\u0026#34;\u0026#34; pass class HomePage(WebPage): def render(self): \u0026#34;\u0026#34;\u0026#34; Code to render HTML of home page \u0026#34;\u0026#34;\u0026#34; pass def save(self): \u0026#34;\u0026#34;\u0026#34; Code to save data of home page into a database \u0026#34;\u0026#34;\u0026#34; pass def delete(self): \u0026#34;\u0026#34;\u0026#34; Code to delete data of home page from a database \u0026#34;\u0026#34;\u0026#34; raise Exception(\u0026#34;Error: Only Admin can delete data from database.\u0026#34;) class AdminPage(WebPage) def render(self): \u0026#34;\u0026#34;\u0026#34; Code to render HTML of admin page \u0026#34;\u0026#34;\u0026#34; pass def save(self): \u0026#34;\u0026#34;\u0026#34; Code to save data of admin page into a database \u0026#34;\u0026#34;\u0026#34; pass def delete(self): \u0026#34;\u0026#34;\u0026#34; Code to delete data of admin page from a database \u0026#34;\u0026#34;\u0026#34; pass The example above violates the ISP because the children should not be forced to depend on the parent\u0026rsquo;s method(s) they do not use. While the AdminPage class inherits just fine, the HomePage class can\u0026rsquo;t use the delete() function. This creates an unnecessary dependency!\nFixed: It will be better to segregate the parent (WebPage) class into smaller interface(s) that meet the needs of each child. We can separate render(), save(), and delete() functions into multiple classes.\nFig. 8: Design refactored to adhere to the Interface Segregation Principle, promoting interface granularity and avoiding client dependencies on unnecessary methods. Code Example class Renderable: def render(self): \u0026#34;\u0026#34;\u0026#34; Code to render HTML of a generic web page \u0026#34;\u0026#34;\u0026#34; pass class Savable: def save(self): \u0026#34;\u0026#34;\u0026#34; Code to save data of a generic web page into a database \u0026#34;\u0026#34;\u0026#34; pass class Deletable: def delete(self): \u0026#34;\u0026#34;\u0026#34; Code to delete data of a generic web page from a database \u0026#34;\u0026#34;\u0026#34; pass class HomePage(Renderable, Savable): def render(self): \u0026#34;\u0026#34;\u0026#34; Code to render HTML of home page \u0026#34;\u0026#34;\u0026#34; pass def save(self): \u0026#34;\u0026#34;\u0026#34; Code to save data of home page into a database \u0026#34;\u0026#34;\u0026#34; pass class AdminPage(Renderable, Savable, Deletable): def render(self): \u0026#34;\u0026#34;\u0026#34; Code to render HTML of admin page \u0026#34;\u0026#34;\u0026#34; pass def save(self): \u0026#34;\u0026#34;\u0026#34; Code to save data of admin page into a database \u0026#34;\u0026#34;\u0026#34; pass def delete(self): \u0026#34;\u0026#34;\u0026#34; Code to delete data of admin page from a database \u0026#34;\u0026#34;\u0026#34; pass Data Science Example Let\u0026rsquo;s say that you are a Data Scientist at LinkedIn who is working on a multimodal application. You are tasked to process image and text data. Like the web development example above, you want separate interfaces for each subtask and inherit related interfaces to process images and text accordingly.\nCode Example class DataLoader: def load(self, data): \u0026#34;\u0026#34;\u0026#34; Code to load data to notebook memory (entire dataset or as a generator) \u0026#34;\u0026#34;\u0026#34; pass class DuplicateRemoval: def remove_dup(self, data): \u0026#34;\u0026#34;\u0026#34; Code to remove duplicate images in the dataset \u0026#34;\u0026#34;\u0026#34; pass class DataAugmentation: def img_augment(self, data): \u0026#34;\u0026#34;\u0026#34; Code to augment images in the dataset \u0026#34;\u0026#34;\u0026#34; pass class DataSmoothing: def ts_smooth(self, data): \u0026#34;\u0026#34;\u0026#34; Code to smooth time-series dataset \u0026#34;\u0026#34;\u0026#34; pass class ProcessTimeSeriesDataset(DataLoader, DataSmoothing): def load(self, data): \u0026#34;\u0026#34;\u0026#34; Code to load data to notebook memory (entire dataset or as a generator) \u0026#34;\u0026#34;\u0026#34; pass def ts_smooth(self, data): \u0026#34;\u0026#34;\u0026#34; Code to smooth time-series dataset \u0026#34;\u0026#34;\u0026#34; pass class ProcessImageDataset(DataLoader, DuplicateRemoval, DataAugmentation): def load(self, data): \u0026#34;\u0026#34;\u0026#34; Code to load data to notebook memory (entire dataset or as a generator) \u0026#34;\u0026#34;\u0026#34; pass def remove_dup(self, data): \u0026#34;\u0026#34;\u0026#34; Code to remove duplicate images in the dataset \u0026#34;\u0026#34;\u0026#34; pass def img_augment(self, data): \u0026#34;\u0026#34;\u0026#34; Code to augment images in the dataset \u0026#34;\u0026#34;\u0026#34; pass Here, we have the defined separate interfaces for data load, removing duplicates, image augmentation, and time-series smoothing. The ProcessTimeSeriesDataset and ProcessImageDataset classes only implement (or inherit) the interfaces (or parent classes) that are relevant to them.\nDependency Inversion Principle DIP: \u0026ldquo;Depend on abstractions. Do not depend on concretions\u0026rdquo; ‚Äî Robert C. Martin. The main idea is to decouple high-level modules from low-level modules by introducing abstractions as mediators. When integrating external dependencies, it is better to create wrapper(s) around them so that your code depends on the wrapper you make and not the details of the dependencies. This allows for better flexibility, as different implementations can be easily substituted without affecting the high-level modules. This principle promotes modularity and maintainability in codebase design.\nFig. 9: Implementation of a wrapper to encapsulate system details and provide a simplified interface to users, shielding them from unnecessary complexity and internal workings (Image source: MonkeyUser.com). Web Development Example Let\u0026rsquo;s say you are a Mobile Developer at Apple who work on the payment integration aspect of Apple Music. Your task is to integrate Stripe Payment API into your backend codebase.\nCode Example class StripeProcessor: def process_payment(self, credit_cart_num): \u0026#34;\u0026#34;\u0026#34; Code to process payment via Stripe Payment API \u0026#34;\u0026#34;\u0026#34; pass class AppleMusic: def notify_payment(self, credit_cart_num): \u0026#34;\u0026#34;\u0026#34; Code to process payment in iOS backend \u0026#34;\u0026#34;\u0026#34; processor = StripeProcessor() processor.process_payment(credit_cart_num) The Apple Music example above violates DIP as the AppleMusic class directly depends on StripeProcessor class, a specific low-level implementation. Imagine that Stripe provides Stripe Payment API version 2.0, which has a massive change in multiple methods. Our AppleMusic (and any other class that uses the StripeProcessor object) will be broken. We will have to fix every single line that uses StripeProcessor\u0026rsquo;s methods.\nFixed: AppleMusic and StripeProcessor classes should depend on abstractions (or a wrapper for StripeProcessor) to avoid such catastrophe. In addition, we can easily swap the external API (e.g., Venmo Payment API) within the wrapper class by having a wrapper.\nFig. 10: Refactoring design with the Dependency Inversion Principle, where high-level modules depend on abstractions, promoting loose coupling and flexibility in the system architecture. Code Example class PaymentProcessor: def process_payment(self, credit_cart_num): \u0026#34;\u0026#34;\u0026#34; Code to process payment via external API \u0026#34;\u0026#34;\u0026#34; pass class StripeProcessor(PaymentProcessor): def process_payment(self, credit_cart_num): \u0026#34;\u0026#34;\u0026#34; Code to process payment via Stripe Payment API \u0026#34;\u0026#34;\u0026#34; pass class VenmoProcessor(PaymentProcessor): def process_payment(self, credit_cart_num): \u0026#34;\u0026#34;\u0026#34; Code to process payment via Venmo Payment API \u0026#34;\u0026#34;\u0026#34; pass class AppleMusic: def __init__(self, processor: PaymentProcessor): \u0026#34;\u0026#34;\u0026#34; Code to build AppleMusic constructor (object) \u0026#34;\u0026#34;\u0026#34; self.processor = processor def notify_payment(self, credit_cart_num): \u0026#34;\u0026#34;\u0026#34; Code to process payment in iOS backend \u0026#34;\u0026#34;\u0026#34; self.processor.process_payment(credit_cart_num) Data Science Example Let\u0026rsquo;s say you are a Data Analyst at Deloitte who is in charge of plotting the dataset to show insight to stakeholders. Similarly to the Apple Music example above, creating a wrapper for the data visualization task would be best.\nCode Example class Plotter: def show_plots(self, dataset): \u0026#34;\u0026#34;\u0026#34; Code to plot the dataset \u0026#34;\u0026#34;\u0026#34; pass class SeabornPlotter(Plotter): def show_plots(self, dataset): \u0026#34;\u0026#34;\u0026#34; Code to plot the dataset bia Seaborn API \u0026#34;\u0026#34;\u0026#34; pass class PlotlyPlotter(Plotter): def show_plots(self, dataset): \u0026#34;\u0026#34;\u0026#34; Code to plot the dataset bia Plotly API \u0026#34;\u0026#34;\u0026#34; pass class BusinessInsight(): def __init__(self, plotter: Plotter): \u0026#34;\u0026#34;\u0026#34; Code to build BusinessInsight constructor (object) \u0026#34;\u0026#34;\u0026#34; self.plotter = plotter def notify_payment(self, dataset): \u0026#34;\u0026#34;\u0026#34; Code to show the visualization trends or patterns of the dataset \u0026#34;\u0026#34;\u0026#34; self.plotter.show_plots(dataset) Here, the BusinessInsight class depends on the Plotter abstraction through its constructor, allowing different plotting implementations to be injected without modifying the BusinessInsight class. The Plotter class serves as the abstraction, while SeabornPlotter and PlotlyPlotter are concrete implementations of the Plotter class. Depending on the abstraction (Plotter), the BusinessInsight class is decoupled from specific plotting implementations. This promotes flexibility and modularity, as different plotting libraries or variations can be used interchangeably by appropriately implementing the Plotter abstraction to the BusinessInsight class.\nCitation Cited as:\nNguyen, Minh. (April 2023). S.O.L.I.D Principles Explained https://mnguyen0226.github.io/posts/solid_principles/post/ Or\n@article{nguyen2023solid, title = \u0026#34;S.O.L.I.D Principles Explained\u0026#34;, author = \u0026#34;Nguyen, Minh\u0026#34;, journal = \u0026#34;mnguyen0226.github.io\u0026#34;, year = \u0026#34;2023\u0026#34;, month = \u0026#34;April\u0026#34;, url = \u0026#34;https://mnguyen0226.github.io/posts/solid_principles/post/\u0026#34; } References [1] R. S. Pressman and B. R. Maxim, Software Engineering: A Practitioner‚Äôs Approach. New York, NY: McGraw-Hill Education, 2020.\n[2] R. C. Martin, M. C. Feathers, T. R. Ottinger, and J. J. Langr, Clean Code A Handbook of Agile Software Craftsmanship. Boston, MA: Pearson Education, Inc, 2016.\n[3] R. C. Martin, ‚ÄúClean Code - Lecture Series,‚Äù YouTube, https://www.youtube.com/watch?v=7EmboKQH8lM\u0026amp;amp;list=PLwAjnlpkQEft41G-GvHAKnh_CkaEKFawh\u0026amp;amp;ab_channel=UnityCoin (accessed May 12, 2023).\n[4] ‚ÄúSOLID Design Principle - Web Dev Simplified,‚Äù YouTube, https://www.youtube.com/watch?v=UQqY3_6Epbg\u0026amp;amp;list=PLZlA0Gpn_vH9kocFX7R7BAe_CvvOCO_p9\u0026amp;amp;ab_channel=WebDevSimplified (accessed May 12, 2023).\nFig. 11: Sunrise at Ho Chi Minh City, Viet Nam (Image source: Peter Nguyen @ Unsplash). ","permalink":"https://mnguyen0226.github.io/posts/solid_principles/post/","summary":"[v.1.0] (04/28/2023): Post published!\nI recently finished an excellent graduate course, Software Engineering (CS5704), and learned about different aspects of software projects and how different-size companies handle their technical/business changes to deliver successful products to their customer. Some important topics are Process Models (Waterfall, V-Model, Spiral, Agile), Requirements Definition, and Architecture Design Patterns. Especially, S.O.L.I.D principles have struck me as must-known concepts for writing better and cleaner code.\nWhy do S.","title":"S.O.L.I.D Principles Explained"},{"content":"[v.1.0] (03/20/2023): Post published!\nDuring a recent interview with a Data Science Lead at a digital agriculture tech company, I had the opportunity to delve into the machine learning team\u0026rsquo;s exciting project. The team was utilizing multi-task learning (MTL) to deploy models to farming hardware, which piqued my interest and prompted me to explore this approach combined with deep learning. In particular, I wanted to investigate the effectiveness of MTL on vision transformers (ViT) and deep residual networks (ResNet-152).\nIn recent years, MTL has gained significant attention as a powerful technique to tackle multiple tasks simultaneously while optimizing computational resources. In computer vision, MTL has shown great potential in addressing challenges such as image segmentation, key-point detection, and edge detection. It has demonstrated remarkable improvements in data efficiency and performance on related tasks. Notably, Andrej Karpathy\u0026rsquo;s work on \u0026ldquo;Tesla Autopilot and Multi-Task Learning for Perception and Prediction\u0026rdquo; highlights how MTL enables the deployment of large models in constrained hardware settings while improving task-specific performance.\nFig. 1: Leveraging Multi-Task Learning for deploying large models in constraint settings (Image Source: Andrej Karpathy @ Tesla). Motivated by these advancements, my goal is to thoroughly investigate the effectiveness of MTL using the ViT architecture for image classification. Additionally, I aim to compare its performance against single-task learning (STL). I focus on class and super-class classification tasks extracted from the popular CiFAR-10 and CiFAR-100 datasets to conduct this investigation. I leverage the power of Python and Tensorflow in implementing and evaluating these experiments. For the convenience of interested readers, I have made the code and results of this research available in my Github repository.\nMulti-Task Learning Multi-Task Learning (MTL) is a powerful technique that allows networks to learn multiple related tasks simultaneously instead of training separate models for each task. MTL offers better efficiency and generalization than Single-Task Learning (STL), making it popular in various fields.\nEfficiency is crucial in embedded applications and deployment, where hardware limitations and cloud storage costs are considerations. MTL optimizes computational resources by jointly learning multiple tasks in a single model, improving efficiency and reducing complexity.\nGeneralization is essential for building artificial generalized intelligence. MTL leverages shared representations to gain a broader understanding of data patterns and correlations, enhancing adaptability to diverse scenarios.\nThere are two main approaches to implementing MTL: \u0026ldquo;hard-parameter\u0026rdquo; sharing and \u0026ldquo;soft-parameter\u0026rdquo; sharing. Hard-parameter sharing involves sharing some or all of the layers between tasks, enabling efficient knowledge transfer and improving model performance. In this post, I explore the application of hard-parameter sharing in image classification, specifically using vision transformers (ViT) and deep residual networks (ResNet-152).\nFig. 2: Comparison of Hard-Parameter Sharing and Soft-Parameter Sharing in Multi-Task Learning (Image inspired from The Gradient). There are three research questions that I want to tackle:\nRQ1: Is an MTL ViT model superior in performance to an MTL Convolution-based model (ResNet-152)? RQ2: Can an MTL ViT model achieve better results than two separate STL ViT models? RQ3: Does an STL ViT model outperform an STL Convolution-based model (ResNet152) in terms of accuracy? CiFAR-10 \u0026amp; CiFAR-100 Datasets For the CiFAR-10 dataset, I have selected two tasks: Task 1 involves a 10-class classification, while Task 2 focuses on binary classification by categorizing the ten classes into \u0026ldquo;animal\u0026rdquo; or \u0026ldquo;vehicle\u0026rdquo; labels. For the CiFAR-100 dataset, I have identified two tasks: Task 1 encompasses a 100-class classification, and Task 2 involves a 20-superclass classification, where the 100 classes are grouped into 20 superclasses, such as aquatic mammals, fish, flowers, and food containers. The dataset details can be found on the University of Toronto\u0026rsquo;s website.\nFig. 3: CiFAR-10 dataset (Image Source: University of Toronto). Vision Transformers (ViT) ViT is an encoder-based transformer neural network that uses a self-attention mechanism to transform the input image into fixed-size patches and encode their positions into the input, allowing the network to capture global features and locations. In contrast, convolutional neural networks (CNN) focus on extracting local features. The ViT architecture consists of the following steps: input, linear projection, stacked encoder, multi-layer perceptron, and output labels.\nFig. 4: Architecture of the Vision Transformers (Image Source: Dosovitskiy, Alexey, et al.). The explanation of ViT is cited from the original paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\u0026quot; by Dosovitskiy, Alexey, et al. The image is first converted into patches, and each patch is reshaped into a 1D vector multiplied by a learnable matrix to create a vector. Next, positional embedding is integrated as ViT is invariant to position on patches. The encoder of ViT is copied directly from the original Transformer architecture. The embedded patches are passed through a Layer Normalization to reduce training time and stabilize the training phases. Then, we pass the information through a multi-head attention network added by a skip connection to improve the performance while reducing the risk of gradient explosion or vanishing. We then pass through another Layer Normalization, Multi-layer Perceptron, and skip connection for further processing. The use of positional embedding allows ViT to behave like CNN, and this is the only inductive bias in ViT. Compared with CNN, ViT enables the network to learn the global and abstract representations of the input image, making it more robust.\nJupyter Notebooks ‚ñ™ Single-Task Learning on CiFAR-10 Dataset: A Vision Transformer Approach. ‚ñ™ Single-Task Learning on CiFAR-10 Dataset - Super-Class Classfication: A Vision Transformer Approach. ‚ñ™ Single-Task Learning on CiFAR-100 Dataset: A Vision Transformer Approach. ‚ñ™ Single-Task Learning on CiFAR-100 Dataset - Super-Class Classfication: A Vision Transformer Approach. ‚ñ™ Multi-Task Learning on CiFAR-10 Dataset: A Vision Transformer Approach. ‚ñ™ Multi-Task Learning on CiFAR-100 Dataset: A Vision Transformer Approach. Deep Residual Network (ResNet-152) Deep residual network-152 layers, also known as ResNet-152, is a convolutional neural network architecture designed to address the vanishing gradient problem in building deep neural networks. It was introduced in the original paper \u0026ldquo;Deep residual learning for image recognition\u0026rdquo; by He, Kaiming, et al.\nFig. 5: Architecture of the ResNet (Image Source: He, Kaiming, et al.). The key innovation of ResNet-152 is the residual block, which allows the network to learn residual functions that map the input to the output, rather than trying to learn the entire mapping in one shot. The residual block consists of two convolutional layers with batch normalization and ReLU activation, and a skip connection that adds the input of the block to the output of the second convolutional layer. Due to its depth, ResNet-152 can capture more complex features and achieve better performance than its shallower counterparts, such as ResNet-18, ResNet-34, and ResNet50. It has been used in various computer vision tasks, such as object detection, image classification, and image segmentation.\nJupyter Notebooks ‚ñ™ Single-Task Learning on CiFAR-10 Dataset (10 Classes): A ResNet-152 Approach. ‚ñ™ Single-Task Learning on CiFAR-10 Dataset (2 Classes): A ResNet-152 Approach. ‚ñ™ Single-Task Learning on CiFAR-100 Dataset (100 Classes): A ResNet-152 Approach. ‚ñ™ Single-Task Learning on CiFAR-100 Dataset (20 Superclasses): A ResNet-152 Approach. ‚ñ™ Mullti-task Learning on CiFAR-10 Dataset: A ResNet-152 Approach. ‚ñ™ Mullti-task Learning on CiFAR-100 Dataset: A ResNet-152 Approach. Experimental Results The experiment result summary can be found here.\nFrom the experimental result, we can answer the three research questions:\nRQ1: Is an MTL ViT model superior in performance to an MTL Convolution-based model (ResNet-152)?\nMTL ViT outperformed MTL ResNet-152 on CiFAR-100, while MTL ResNet-152 outperformed MTL ViT on CiFAR-10 regarding testing accuracies. This result suggests that the MTL ViT is better suited for complex classification tasks, as CiFAR-100 is a more complex dataset than CiFAR-10. With more complex datasets or longer training epochs, I expect MTL ViT to outperform MTL ResNet-152 on both datasets.\nRQ2: Can an MTL ViT model achieve better results than two separate STL ViT models?\nMTL ViT outperformed two STL ViTs on CiFAR-10 and CiFAR-100 regarding testing accuracies. This result aligns with previous studies on benchmark datasets such as Taskonomy, Replica, and CocoDoom. The superior performance of MTL ViT is due to the sharing of the same backbone between the two tasks, which enables the network to learn more representations while significantly reducing the number of parameters.\nRQ3: Does an STL ViT model outperform an STL Convolution-based model (ResNet152) in terms of accuracy?\nFor this question, there is no clear answer. If we use a more complex dataset or train with more epochs, we might see that ViT outperforms ResNet152 in CiFAR-10 and CiFAR-100. ViT can capture global features due to its positional embedding and attention mechanism, while ResNet-152 can capture local features due to the convolutional operation.\nCitation Cited as:\nNguyen, Minh. (March 2023). Multi-Task Learning for Image Classification https://mnguyen0226.github.io/posts/multitask_learning/post/ Or\n@article{nguyen2023mtl, title = \u0026#34;Multi-Task Learning for Image Classification\u0026#34;, author = \u0026#34;Nguyen, Minh\u0026#34;, journal = \u0026#34;mnguyen0226.github.io\u0026#34;, year = \u0026#34;2023\u0026#34;, month = \u0026#34;March\u0026#34;, url = \u0026#34;https://mnguyen0226.github.io/posts/multitask_learning/post/\u0026#34; } References [1] Y. Chen, J. Yu, Y. Zhao, J. Chen, and X. Du. Task‚Äôs choice: Pruning-based feature sharing (pbfs) for multi-task learning. Entropy, 24(3):432, 2022.\n[2] M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele. The cityscapes dataset for semantic urban scene understanding. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3213‚Äì3223, 2016.\n[3] M. Crawshaw. Multi-task learning with deep neural networks: A survey. arXiv preprint arXiv:2009.09796, 2020.\n[4] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020.\n[5] Evannex. Andrej karpathy talks tesla autopilot amp; multitask learning, Aug 2019.\n[6] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770‚Äì778, 2016.\n[7] A. Krizhevsky, V. Nair, and G. Hinton. Cifar-10 and cifar100 datasets. URl: https://www. cs. toronto. edu/kriz/cifar.html, 6(1):1, 2009.\n[8] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollar, and C. L. Zitnick. Microsoft coco: Common objects in context. In Computer Vision‚ÄìECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13, pages 740‚Äì755.Springer, 2014.\n[9] A. Mahendran, H. Bilen, J. F. Henriques, and A. Vedaldi. Researchdoom and cocodoom: Learning computer vision with games. arXiv preprint arXiv:1610.02431, 2016.\n[10] I. Misra, A. Shrivastava, A. Gupta, and M. Hebert. Crossstitch networks for multi-task learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3994‚Äì4003, 2016.\n[11] S. Ruder. An overview of multi-task learning in deep neural networks. arXiv preprint arXiv:1706.05098, 2017.\n[12] J. Straub, T. Whelan, L. Ma, Y. Chen, E. Wijmans, S. Green, J. J. Engel, R. Mur-Artal, C. Ren, S. Verma, et al. The replica dataset: A digital replica of indoor spaces. arXiv preprint arXiv:1906.05797, 2019.\n[13] A. R. Zamir, A. Sax, W. Shen, L. J. Guibas, J. Malik, and S. Savarese. Taskonomy: Disentangling task transfer learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3712‚Äì3722, 2018.\n[14] X. Zheng, B. Wu, X. Zhu, and X. Zhu. Multi-task deep learning seismic impedance inversion optimization based on homoscedastic uncertainty. Applied Sciences, 12(3):1200, 2022.\nFig. 6: Sunset over Minneapolis, Minnesota, U.S.A (Image Source: Nicole Geri @ Unsplash). ","permalink":"https://mnguyen0226.github.io/posts/multitask_learning/post/","summary":"[v.1.0] (03/20/2023): Post published!\nDuring a recent interview with a Data Science Lead at a digital agriculture tech company, I had the opportunity to delve into the machine learning team\u0026rsquo;s exciting project. The team was utilizing multi-task learning (MTL) to deploy models to farming hardware, which piqued my interest and prompted me to explore this approach combined with deep learning. In particular, I wanted to investigate the effectiveness of MTL on vision transformers (ViT) and deep residual networks (ResNet-152).","title":"Multi-Task Learning for Image Classification"},{"content":"üë®‚Äçüíª Experience Data Engineer Intern @ Homebase (Y-Combinator) ‚ñ™ Tech Stack: Python (Scrapy, Selenium, Pandas), PHP, Redis, Airflow, PostgreSQL, AWS. ‚ñ™ Date: 06/2023 - 9/2023. ‚ñ™ Location: Ho Chi Minh City, Vietnam (Remote). Responsibilities ‚ñ™ Developed a distributed web‚Äëscraper with Python (Scrapy, Selenium, Pandas), Redis, and Airflow, reducing runtime by 75%. ‚ñ™ Automated ETL from WordPress to Strapi CMS with PHP, Pandas, RESTful APIs, PostgreSQL, and AWS S3, reducing operational time by 25%. ‚ñ™ Built a WordPress blog website using AWS EC2, boosting traffic organically from search engines. Graduate Research Assistant @ CS Department (Virginia Tech) ‚ñ™ Tech Stack: Python (Dash, Plotly), Docker, Kubernetes. \u0026nbsp; \u0026nbsp; ‚ñ™ Date: 04/2023 - Present. ‚ñ™ Location: Falls Church, Virginia. Responsibilities ‚ñ™ Designed and built an interactive website for statistics and ML algorithms visualization with Python (Dash, Plotly) and Docker. ‚ñ™ Deployed the website on Kubernetes cluster, ensuring scalability and reliability. Graduate Research Assistant @ Commonwealth Cyber Initiatives (Virginia Tech) ‚ñ™ Tech Stack: Python, Tensorflow, Matplotlib, Pandas, Seaborn. ‚ñ™ Date: 05/2022 - 08/2022. ‚ñ™ Location: Arlington, Virginia. Responsibilities ‚ñ™ Developed and fine‚Äëtuned RNN, LSTM, and Transformer forecasting models with Python and Tensorflow, reducing operational costs by 30%. ‚ñ™ Enhanced time‚Äëseries data quality via data cleaning, feature engineering, exploratory data analysis (EDA) using Pandas and Plotly. ‚ñ™ Designed and implemented the visualization dashboard with Python and Dash for seamless integration of ML into existing SCADA system. ‚ñ™ Boosted prediction accuracy by 4% and doubled database records by implementing TimeGAN data synthesis model. Research Assistant @ Terrestrial Robotics Engineering \u0026 Controls Lab (Virginia Tech) ‚ñ™ Tech Stack: C#, C++, Unity. \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; ‚ñ™ Date: 09/2021 - 05/2022. ‚ñ™ Location: Blacksburg, Virginia. Responsibilities ‚ñ™ Improved transparency by applying ROS-Bridge data transfer pipeline between the low-level robotic controller and Unity. ‚ñ™ Created 3D interactive simulation environments in Unity with VR headsets and Haptix Gloves synchronization. ‚ñ™ Poster, Presentation. Machine Learning Intern @ Heron Systems (Shield AI Subsidiary) ‚ñ™ Tech Stack: Python, Javascript, PyTorch, Pandas, Plotly, SpaCy, Flask, MySQL. ‚ñ™ Date: 05/2021 - 08/2021. ‚ñ™ Location: Alexandria, Virginia. Responsibilities ‚ñ™ Developed and refined the classification model using Python and PyTorch, predicting battle outcomes for DARPA‚Äôs Game Breaker. ‚ñ™ Determined optimal pre‚Äëdeployment configurations for LSTM, GRU, and Transformer models by evaluating them using IMDb dataset. ‚ñ™ Built the dashboard with Python, Dash, and SQLAlchemy of the models, aiding in the securement of DARPA‚Äôs $1M second funding round. Research Assistant @ Geo Lab (William \u0026 Mary College) ‚ñ™ Tech Stack: Python, Tensorflow, Matplotlib. ‚ñ™ Date: 09/2020 - 05/2021. ‚ñ™ Location: Williamsburg, Virginia. Responsibilities ‚ñ™ Led a team to develop CNN models (ResNet, VGG, Inception‚ÄëV3) with Python and Tensorflow for satellite‚Äëimage‚Äëbased road quality classification. ‚ñ™ Enhanced benchmark dataset by 40% through efficient data collection and class balancing using image augmentation techniques. ‚ñ™ Mitigated 70% of data‚Äëpoisoning attacks on the model by implementing and fine‚Äëtuning an Auto‚ÄëEncoder. ‚ñ™ Achieved 3rd place among eight competing universities. Research Assistant @ Hybrid Electric Vehicle Team (Virginia Tech) ‚ñ™ Tech Stack: C++, MATLAB. \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; ‚ñ™ Date: 09/2020 - 05/2021. ‚ñ™ Location: Blacksburg, Virginia. Responsibilities ‚ñ™ Applied Sensor Fusion algorithm to Chevrolet Blazer 2019 by integrating/testing Borsh radar and Mobileye6 camera sensors. ‚ñ™ Implemented and tested the algorithm's performance in simulation; earned full points in the EcoCar Competition's road driving tests. Teaching Assistant @ Integrate System Design (Virginia Tech) ‚ñ™ Tech Stack: C++, Circuit Design, Arduino, MIT Mobile App Inventor. ‚ñ™ Date: 05/2020 - 05/2021. ‚ñ™ Location: Blacksburg, Virginia. Responsibilities ‚ñ™ Conducted 3 two‚Äëhour office sessions and graded labs for 50+ students 2 times per week. ‚ñ™ Proactively addressed student inquiries on micro‚Äëcontroller applications and software development in C. Research Assistant @ Wireless Lab (Virginia Tech) ‚ñ™ Tech Stack: C++, Python. ‚ñ™ Date: 05/2020 - 08/2020. ‚ñ™ Location: Blacksburg, Virginia. Responsibilities ‚ñ™ Designed a controller with two stepper motors using Python, Arduino, and GRBL library for long-range signal receiving or signal sweeping tasks. The user can control the Antenna's movements through their preferred angles by entering the angles in the Python scripted interface. üîß Skills Frontend: JavaScript, TypeScript, HTML5, CSS, SCSS | React.js, Next.js, Vue.js. Backend: Python, Java, SQL, C++, C | Flask, Dash, Node.js, RESTful API | MySQL, SQLite, PostgreSQL. Data Science Tools: Tensorflow, PyTorch, Scikit-learn, NumPy, Matplotlib, Pandas, Seaborn, Plotly, BeautifulSoup, OpenCV. Others: Docker, Kubernetes, AWS, Git, Linux. üéì Education Master of Science in Computer Engineering ‚ñ™ Concentration: Software \u0026 Machine Intelligence. ‚ñ™ GPA: 3.75. ‚ñ™ Date: 08/2022 - Present. ‚ñ™ Location: Falls Church, Virginia. Bachelor of Science in Computer Engineering (Graduated) ‚ñ™ Concentration: Machine Learning, Computer Science Minor. ‚ñ™ GPA: 3.60. ‚ñ™ Date: 08/2018 - 05/2022. ‚ñ™ Location: Blacksburg, Virginia. Relevant Courses ‚ñ™ Deep Learning ‚ñ™ Web Application Development ‚ñ™ Software Engineering ‚ñ™ Data Visualization ‚ñ™ Advanced Machine Learning ‚ñ™ Trustworthy Machine Learning ‚ñ™ Data Analytics ‚ñ™ Computer Vision ‚ñ™ Digital Image Processing ‚ñ™ AI \u0026 Engineering Applications ‚ñ™ Real-time Systems ‚ñ™ Data Structure \u0026 Algorithms ‚ñ™ Principles Of Computer Architecture üìú Publications \"DeepH20: Cyber attack detection in water distribution systems using deep learning.\" Nazmul Sikder, Minh T. Nguyen, Donald Elliot, Feras Batarseh. Elsevier's Journal of Water Process Engineering (Vol 52.) (04/2023). Link.\n\"AI for Cyberbiosecurity in Water Systems‚ÄîA Survey.\" Daniel Sobien, Mehmet O. Yardimci, Minh T. Nguyen, Wan-Yi Mao, Vinita Fordham, Abdul Rahman, Susan Duncan, Feras Batarseh. Springer's Cyberbiosecurity Book (01/2023). Link.\nüíª Projects Machine Learning Algorithms Visualization ‚ñ™ Tech Stack: Python, Dash, Bootstrap, Docker, Kubernetes, HTML, CSS. \u0026nbsp; \u0026nbsp; ‚ñ™ Designed and built the user‚Äëfriendly website to aid CS students in effectively comprehending complex ML and statistics concepts. ‚ñ™ Dockerized and deployed the website on Virginia Tech‚Äôs Rancher (Kubernetes) cluster to improve scalability and reliability. ‚ñ™ Link. Web Bookstore ‚ñ™ Tech Stack: Java, Vue.js, MySQL, Figma, HTML, CSS. \u0026nbsp; \u0026nbsp; ‚ñ™ Developed the single‚Äëpage website with client/server‚Äëside transaction validation, session handling, and user history tracking. ‚ñ™ Implemented the middleware and RESTful APIs with Java Servlet, Apache Tomcat and MySQL database. ‚ñ™ Employed the Data Access Object (DAO) design pattern and adhered to SOLID principles, ensuring the modular and maintainable system. ‚ñ™ Github. Web News ‚ñ™ Tech Stack: Python, Javascript, MySQL, Flask API, Werkzeug API, CKEditor API, Bootstrap, HTML, CSS. \u0026nbsp; \u0026nbsp; ‚ñ™ Transformed Y Combinator‚Äôs Hacker News into a user‚Äëcentric web app, leveraging RESTful APIs for efficient data interchange. ‚ñ™ Developed a multi‚Äëpage functionality including user registration, login, post management, commenting system, and voting mechanism. ‚ñ™ Github. Smart Home Simulation ‚ñ™ Tech Stack: C++, Circuit Design, Arduino, MIT Mobile App Inventor. \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; ‚ñ™ Designed, built, and tested hardware simulation with 8 automated sensors, controlled wirelessly via an Android mobile app. ‚ñ™ Appointed to class's teaching assistant by professor due to project's design, presentation, report, and assistance to classmates. ‚ñ™ Github. üèÖ Awards Best ML Poster @ FLAIRS-35 ‚ñ™ Best journal poster for ML applications in cyberbiosecurity, awarded by juries amongst 40+ submissions. ‚ñ™ Link. Turing Research Fellowship @ Commonwealth Cyber Initiatives ‚ñ™ Awarded AI Fellowship out of 21 universities in the Commonwealth of Virginia state. ‚ñ™ Link. Geo Research Fellowship @ Geo Lab ‚ñ™ One of 30 fellows (out of 150 applicants) for the US's largest geospatial data security lab. ‚ñ™ Link. üôå Volunteers President @ Teaching Robotics \u0026 Engineering Club (Virginia Tech) ‚ñ™ Taught C/C++, Arduino, and electric foundations and robotics projects for 15-25 club members. ‚ñ™ Supervised club Officers in making teaching materials and mentoring club members. Industry Relations Chair @ IEEE Student Branch (Virginia Tech) ‚ñ™ Tripled the number of participants by hosting peer networking events and info sessions to connect students to faculty-sponsored and company-sponsored opportunities in the ECE department. ‚ñ™ Collaborated with company representatives in IEEE@VT Summit, resume review sessions, and tech talks. ‚ñ™ Raised a $6,000 annual sponsorship from Collins Aerospace, Lockheed Martin, Boeing, and Texas Instruments. Student Mentor @ Center for Enhancement of Engineering Diversity (Virginia Tech) ‚ñ™ Served as a sounding board for various issues that confront first-year students during the first 10 weeks. ‚ñ™ Held weekly meetings to provide 10 mentees about how to smoothly transition into Virginia Tech culture. Officer @ IEEE Student Branch (Virginia Tech) ‚ñ™ Organized ‚ÄúFun Friday‚Äôs‚Äù peer networking events and the IEEE Summit industry/leadership conference. Captain @ Math Team (St. Paul Preparatory School) ‚ñ™ Won Team Second Place in the 2017 Minnesota High School Mathematics League Tournament. ‚ñ™ Assisted the teacher with explaining difficult problems to members. ‚ñ™ Assigned math areas to different teammates based on skill sets to boost the team's total score. ","permalink":"https://mnguyen0226.github.io/about/","summary":"üë®‚Äçüíª Experience Data Engineer Intern @ Homebase (Y-Combinator) ‚ñ™ Tech Stack: Python (Scrapy, Selenium, Pandas), PHP, Redis, Airflow, PostgreSQL, AWS. ‚ñ™ Date: 06/2023 - 9/2023. ‚ñ™ Location: Ho Chi Minh City, Vietnam (Remote). Responsibilities ‚ñ™ Developed a distributed web‚Äëscraper with Python (Scrapy, Selenium, Pandas), Redis, and Airflow, reducing runtime by 75%. ‚ñ™ Automated ETL from WordPress to Strapi CMS with PHP, Pandas, RESTful APIs, PostgreSQL, and AWS S3, reducing operational time by 25%.","title":"About Me"},{"content":"[v.1.0] (01/20/2023): Post started!\nComputer Memory \u0026amp; Storage Storage HDD (hard disk drive): it works by spinning magnetics disk. SSD (solid state drive): it uses NAND-based flash memory, providing fast data access, reduces power consumption, and increases durability. It is more expensive. USB Drive: is a small plug-and-play device for convenient data transfer between computers. SD Card is commonly found in camera and smartphone. There is SD Card, Mini Card, and Micro Card. Memory RAM (random access memory): is a type of memory that store data temperarily while the computer is running. It\u0026rsquo;s fast and flexible. However, all the data is lost after the power is off. SRAM (static random access memory): is a fast and expensive DRAM used in high speed application like CPU caches, where quick access time is crucial. DRAM (dynamic random access memory): is slower and cheaper than SRAM. It needs to be constantly refreshed to maintain data. SDRAM DDR SDRAM: with examples like DDR4, DDR5. GGDDR SDRAM: is a specialized of DRAM with faster data transfer rates for parallel processing. ROM (read only memory): is a type of memory that retains data, even when the memory is off. It is used to store essential information like firmware and BIOS. Firmware: is a type of software stored in ROM that determines how hardware devices communicate with each others BIOS (basic input-output systems): first run when you booth up the computer. It is responsible for starting your computer, initializes hardware components, and hands over controls to the OS. Domain Name System (DNS) It is the backbone of the internet.\nBut how does it work?\nDNS is a directory: it translates human-readable domain names (i.e, www.google.com) to machine-readable IP-addresses.\nThere are different DNS servers with different purposes. The DNS Resolver can be provided by Cloudflare (1.1.1.1) or Google (8.8.8.8).\nHow does the DNS Resolver find the authoritative nameservers?\nThere are 3 levels of DNS:\nRoot Nameservers: stores the IP-addresses of the TLD nameservers. There are 13 logical Root Nameservers. Ex: .com, .org, .edu Top Level Domain (TLD) Nameservers: stores the IP-addresses of the Authoritative Nameservers. Ex: google.com, wikipedia.org, mit.edu. Authoritative Nameservers: stores authoritative answers to queries Such design above make DNS decentralized and robust.\nHow does the workflow look like?\nFig. 1: DNS workflow (Image source: ByteByteGo.com). The user types \u0026ldquo;google.com\u0026rdquo; to browser. The browser first checks its cache, if there is no answer, it makes the OS call to get the answer. The OS then reachs out to DNS Resolver. The DNS Resolver first checks its cache, if it is not there or if the answer is expired, it will ask the Root Nameservers. The Rootname Servers responses with the root name TLD Nameservers. Here, if the RootName Servers found the root name TLD Nameservers (i.e. .com as it is common) in its cache, it will return. The DNS Resolver then reachout to the TLD Nameservers, which return the Authoritative Nameservers for \u0026ldquo;google.com\u0026rdquo;. The DNS Resolver then reachout to the Authoritative Nameservers and get the IP-address of \u0026ldquo;google.com\u0026rdquo;. The DNS Resolver then returns the address of the IP system to the OS, and the OS returns it to the browswer. Common Latency Numbers Fig. 2: Latency number hierachy (Image source: ByteByteGo.com). 1 ns: Accessing CPU registers, CPU clock cycle. 1-10 ns: L1/L2 cache, Branch mispredict. 10-100 ns: L3 cache. 100-1000 ns: System call, MD5 hash. 1-10 ¬µs: Context switches between threads. 10-100 ¬µs: Higher level operations such as process a http request, sequential read, read a 8K page. 100-1000 ¬µs: SSD write latency, intra-zone networking round trip, memcache/redis get operation. 1-10 ms: Intra-zone network latency, seek time of HDD. 10-100 ms: Network round-trip from US West-East. 100-1000 ms: Bcrypt a password, TLS handshake, reading sequentially 1GB of SSD. 1 s: Tranfer 1GB over the network within the same cloud region. REST API Representational State Transfer Application Programming Interface (REST API) is the most popular communication standard between computers over Internet. API is a way for two computers to talk to each other. The common API used by mobile and web applications to talk to the servers is called REST. For instance, Twilio, Stripe, Google Maps use REST API.\nREST is not a specification, it is a loose set of rules for building web API since the early 2000s. Those rules are:\nUniform Interface. Client-Server. Stateless. Cacheable. Layered System. Code on Demand (Optional). Basics of REST API The REST API organizes resources into a set of unique Uniform Resource Identifiers (URIs). The URIs differentiate types of resources on a server.\nhttps://example.com/api/v3/products https://example.com/api/v3/users A client connects to resources by making a request to the endpoint for the resource over HTTP. The request has a specific format such as POST/products HTTP/1.1.\nHere are the operations (CRUD)\nPOST: CREATE a new resource. GET: READ the data about an existing resource. PUT: UPDATE an existing resource. DELETE: DELETE an existing resource. In the body of these request, there could be an optional HTTP request body that contains a custom payload of data, usually encoded in JSON.\nPOST/produccts HTTP/1.1 Accept: application/json JSON: { \u0026#34;customer\u0026#34;: \u0026#34;Minh Nguyen\u0026#34;, \u0026#34;quantity\u0026#34;: 1, \u0026#34;price\u0026#34;: 19.00 } The server receives a request, processes it and form the result into response.\nHTTP/1.1 200 OK Some HTTP status codes:\n200: Request is successful. 400: Something is wrong with our request, such as wrong syntax. 500: Something is wrong at the server level, such as the server is not available. Stateless A REST implementation should be stateless. This means that the two parties don\u0026rsquo;t need to store any information about each other, and every request and response (cycle) is independent from all others. This attribute leads to the web application that is easy to scale and well behaved.\nPagination If the return endpoint returns a huge amount of data, we should use pagination. A common scheme uses limit and offset as parameters. If they are not specified, the server should assume sensible default values.\n/products?limit=25\u0026amp;offset=50 Versioning Versioning allows an implementation to provide backward compatibility, so that if we introduce breaking changes from one version to another, consumers can get enough time to move to the next version.\nThere are many ways to versioning an API. The most common way is to prefix the version before the resource on the URI.\n/v1/products /v2/products RESTful API is sensible if used correctly as it is simple and good enough, and that\u0026rsquo;s why it is so widely used. Other options are GraphQL and gRPC.\n10 Key Data Structures in System Design The choice of correct data structures based on the specification and constraints of the projects is important. To refresh the fundamentals of these data structures, please visit https://neetcode.io/.\nLinked List Linked list (or list) is a versatile and essential data structure in software development. It is great for storing and manipulating ordered data. They are useful in various applications such as task-management, social media feeds, and shopping carts.\nFor task-management application, a list can be used to store and organize tasks for each user. Tasks can be added, removed, or reordered easily, and users can mark them as complete or incomplete.\nIn social media application, e.g. Twitter (X), where they can store and display a users\u0026rsquo; feeds in real-time, ensuring the order is correct in real-time.\nArray Array provdes a fixed-size, ordered collection of elements. They are suitable for situation where the size of the collections is known or isn\u0026rsquo;t changed frequently. Arrays are commonly used in mathematical operations, storing large datasets, or when there is a need for random access to elements.\nFor instance, in the weather application, an array can store temperature readings for a specific location over a defined period. This allows for easy calculations like average temperature or trends analysis.\nArrays are also used in image-processing, where each pixel\u0026rsquo;s color data can be represented in a 2D array. It enables efficient manipulation and transformation of the image.\nStack Stacks follow the LIFO principle, and they are perfect for supporting undo/redo operations in text editors or maintaining browsing history in web browsers.\nIn the text editors, a stack can be used to store each change made to the text, making it simple to revert to a previous state when the user triggers an undo operation.\nQueue Queues operate on the FIFO principle, and they are good for managing printer jobs, sending actions in games, or handling messages in chat applications. Specifically, in chat applications, a queue can be used to store incoming messages in the order they are received. It ensures that they are displayed to the recipient in the correct sequence.\nHeap Heaps are used for task scheduling and memory management. They are helpful in implementing priority queues where we need to access the highest or lowest priority item efficiently.\nTree Trees organize data hierarchically. They are useful for representing data with natural hierarchies or relationships. Trees are used in database indexing, file systems, or AI decision tree.\nFor database indexing, tree helps speed up search, insert, or delete operations. For example, B-trees and B+ trees are commonly used in relational databases to efficiently manage and index large amount of data.\nHash Table Hash table (or hashmap) allows for efficent data lookup, insertion, and deletion. They use a hash function to map keys to their corresponding storage locations. It enables constant-time access to the stored values. Hash tables are widely used in various applications, such as search engines, caching systems, and programming language interpreters or compilers.\nIn search engine, hash table allows to store and quickly retrieve indexed data based on keywords. This provides fast and relevant search results.\nCaching systems may use hash tables to store and manage cached data. It allows for eapid access to frequently requested resources and improves overall system performance.\nSuffix Tree Suffix trees (or tries) are specialized for searching strings in documents. This makes them perfect for text editors and search algorithms. In a search engine, a suffix tree can be used to efficiently locate all occurrences of a search term within a larger corpus of text.\nGraph Graphs are all about tracking relationships or finding paths. This makes them invaluable in social networks, recommendation engines, and pathfinding algorithms.\nIn a social network, a graph can be used to represent a connections between users. It enables features like friend suggestion or analyzing network trends.\nR-tree R-trees are good at finding nearest neighbors. They are crucial for mapping apps and geolocation services. In a mapping applications, R-trees can be used to store spatial data, such as points of interest. This enables efficient queries to find the nearest locations based on the user\u0026rsquo;s current position.\nCache Friendliness Relations to Data Structures CPU cache is a small, fast memory between the main memory (RAM) and the CPU. It stores recently accessed data and instructions, so the CPU can access them quickly without fetching them from the slower main memory.\nDifferent data structures have different levels of cache friendliness based on how their elements are stored in memory. Contiguous memory storage (arrays) allows for better cache locality and fewer cache misses, resulting in improved performance. When an array element is accessed, the cache can be prefetch and store nearby elements, anticipating that they might be accessed soon. While data structures with non-contiguous memory storage (linked-list) can experience more cache misses and reduce performance. In a linked list, elements are stored in nodes scattered throughout the memory and each node contains a pointer to the next node in the sequence. This makes it difficult for the CPU to predict and load the next node before it\u0026rsquo;s needed.\nOther data structures have varying degrees of cache friendliness based on their implementation and use case. This disparity in access times can lead to performance issues in modern computing, particularly in situations where cache misses occur frequently.\nCache Systems Caching is a common technique in modern computing to system performance and reduce response time. From the front-end to back-end, caching plays a crucial role in improving the efficiency of various applications and systems.\nA typical system architecture involves several layers of caching. At each layer, there are multiple strategies and mechanisms for caching data, depending on the requirements and constraints of the specific application.\nComputer Caching Mechanism The most common hardware cache are L1, L2, and L3 caches.\nL1 cache (KBs) is the smallest and fastest cache, typically integrated into the CPU itself. It stores frequently accessed data and instructions, allowing the CPU to quickly access them without having to fetch them from slower memory. L2 cache (MBs) is larger but slower than L1. It is typically located on the CPU die or on a separate chip. L3 cache is larger but slower than L2. It is typically shared between multiple CPU cores. Another common hardware cache is the translation lookaside buffer (TLB). It stores recently used virtual-to-physical address translations. It is used by the CPU to quickly translate virtual memory addresses to physical memory addresses, reducing the time needed to access data from memory\nAt the OS level, there are page cache and other file system caches. Page cache is managed by the OS and resides in the main memory. It is used to store recently used disk blocks in memory. When a program requests data from the disk, the OS can quickly retrieve the data from memory instead of reading it from disk. There are other caches managed by the OS, such as inode cache. These caches are used to speed up file system operations by reducing the number of disk accesses required to access files and directories.\nCache in System Architecture Fig. 3: Cache in System Architecture (Image source: ByteByteGo.com). Front-end: web browsers can cache HTTP response to enable faster retrieval of data. When we request data over HTTP for the first time and it returned with an expiration policy in the HTTP header; we request thee same data again, and the broweser returns the data from its cache if available.\nCDNs: are used to improve the delivery of static contents (images, videos, web assets). When a user requests a content from a CDN, the CDN network looks for the requested content in its cache. If the content is not already in the cache, the CDN fetches it from the origin server and caches it on its edge servers. When another user requests the same content, the CDN can deliever the content directly from its cache, eliminating the need to fetch it from the origin server again.\nLoad-balancers: implement cache resources to reduce the load on back-end servers. When a user requests content from a server behind a load balancer, the load balancer can cache the response and server it directly to future users who request the same content. This can improve response times and reduce the load on back-end servers.\nMesseging infrastructure, message brokers such as Kafka can cache a massive amount of messages on disk. This allows consumers to retrieve the message at their own pace. The messages can be cached for a long period of time based onthe retention policy.\nDistributed caches such as Redis can store key-value pairs in memory, providing high read/write performance compared to traditional databases.\nFull-text search engines like Elastic Search can index data for document search and log search, providing quick and efficient access to specific data.\nRelational database: has multiple levels of caching:\nData is typicaly written to WAL (write-ahead-log), before indexed in a B-tree. Buggerpool is a memory area used to cache query results. Materialized-view can precompute query results for faster performance. Transaction-log records all transactions and updates to the database. Replication-log tracks the replication state in the database cluster. Redis\u0026rsquo;s Versitality Redis is an in-memory data structure store. It is most commonly used as a cache. It support many data structure such as strings, hashes, lists, sets, and sorted sets. Redis is known for its speed.\nCache The number one use case for Redis is caching objects to speed up web applications. Here, Redis stores frequently requested data in memory. They allows the web servers to return frequently accessed data quickly. This reduces the load on the database and improves the response time for the application.\nAt scale, the cache is distributed among a cluster of Redis servers. Sharding is a common technique to distribute the cache load evenly across the cluster.\nSession Redis can be used as a session storage to share session data among stateless servers. When a user logs into a web application, a session data is stored in Redis along with a unique session ID that is returned to the client as cookie. When the user makes a request to the application, the session ID is included in the request and the stateless web server retrieves the session data from Redis using the ID.\nRedis is an in-memory database. The session data stored in Redis will be lost if the Redis server restarts. Even through Redis provides persistence options like snapshots or AOF (Append-Only File) that allow session data to be saved to disk and reloaded into memory in the event of a restart, these options often take too long to load on restart to be practical.\nIn production, replication is usually used instead such as back-up instance. If there is a crash, the back-up instance will be promoted to take over the traffic.\nDistributed Lock Distributed locks are used when multiple nodes in an application need to coordinate access to some shared resource. Redis is used as a distributed lock with is atomic commands like SETNX (set if not exist). The command allows a caller to set a key only if it does not already exist.\nFor instance, client_1 tries to acquire the lock by setting a key with a unique value and a timeout using the SETNX command, SETNX lock \u0026quot;1234abcd\u0026quot; EX 3. If the key was not already set, the SETNX command returns 1, indicating that the lock has been acquired by client_1. client_1 finishes its work and releases the lock by deleting the key. If the key was already set, the SETNX command returns 0, indicating that the lock is already held by another client. In this case, client_1 waits and retries the SETNX until the lock is released by other client.\nRate Limiter Redis can be used as a rate limiter by using its increment command on some counters and setting expiration times on those counters.\nBasic rate-limiting: For each incoming request, the request IP or user ID is used as a key. The number of requests for the key is incremented using the INCR command in Redis. The current count is compared to the allowed rate limit. If the count is within the rate limit, the request is processed. If the count is over the rate limit, the request is rejected. The keys are set to expire after a specific time-window (minutes) to reset the counts for the next time window.\nThere is also a Leaky Bucket Algorithm implemented using Redis.\nRank/Leaderboard For most games that are not super high scale, Redis is a way to implement various types of gaming leaderboards. Sorted Sets (or sorted container or sorted hashmap) are the fundamental data structure that enables this. Here, we can retrieve the data in O(logN).\nCitation Cited as:\nSystem Design Fundamentals Mega-Blog https://mnguyen0226.github.io/posts/system_design_concepts/post/ Or\n@article{nguyen2023sdmega, title = \u0026#34;System Design Fundamentals Mega-Blog\u0026#34;, author = \u0026#34;Nguyen, Minh\u0026#34;, journal = \u0026#34;mnguyen0226.github.io\u0026#34;, year = \u0026#34;2023\u0026#34;, month = \u0026#34;January\u0026#34;, url = \u0026#34;https://mnguyen0226.github.io/posts/system_design_concepts/post/\u0026#34; } References [1] A. Xu, System Design Interview - An Insider‚Äôs Guide. Independently Published, 2020. ‚Äå\n[2] ByteByteGo, ‚Äú10+ Key Memory \u0026amp; Storage Systems: Crash Course System Design #5,‚Äù YouTube. Mar. 28, 2023. Accessed: Oct. 25, 2023. [YouTube Video]. Available: https://www.youtube.com/watch?v=lX4CrbXMsNQ\u0026amp;list=PLCRMIe5FDPsd0gVs500xeOewfySTsmEjf ‚Äå\n[3] ByteByteGo, ‚ÄúLatency Numbers Programmer Should Know: Crash Course System Design #1,‚Äù YouTube. Oct. 04, 2022. Accessed: Oct. 31, 2023. [YouTube Video]. Available: https://www.youtube.com/watch?v=FqR5vESuKe0\u0026amp;list=PLCRMIe5FDPsd0gVs500xeOewfySTsmEjf\u0026amp;index=3 ‚Äå\n[4] ByteByteGo, ‚ÄúWhat Is REST API? Examples And How To Use It: Crash Course System Design #3,‚Äù YouTube. Aug. 24, 2022. Accessed: Oct. 31, 2023. [YouTube Video]. Available: https://www.youtube.com/watch?v=-mN3VyJuCjM\u0026amp;list=PLCRMIe5FDPsd0gVs500xeOewfySTsmEjf\u0026amp;index=4 ‚Äå\n[5] ByteByteGo, ‚Äú10 Key Data Structures We Use Every Day,‚Äù YouTube. May 01, 2023. Accessed: Oct. 31, 2023. [YouTube Video]. Available: https://www.youtube.com/watch?v=ouipSd_5ivQ\u0026amp;list=PLCRMIe5FDPsd0gVs500xeOewfySTsmEjf\u0026amp;index=5 ‚Äå\n[6] ByteByteGo, ‚ÄúCache Systems Every Developer Should Know,‚Äù YouTube. Apr. 04, 2023. Accessed: Oct. 31, 2023. [YouTube Video]. Available: https://www.youtube.com/watch?v=dGAgxozNWFE\u0026amp;list=PLCRMIe5FDPsd0gVs500xeOewfySTsmEjf\u0026amp;index=6 ‚Äå\n[7] ByteByteGo, ‚ÄúTop 5 Redis Use Cases,‚Äù YouTube. Feb. 16, 2023. Accessed: Oct. 31, 2023. [YouTube Video]. Available: https://www.youtube.com/watch?v=a4yX7RUgTxI\u0026amp;list=PLCRMIe5FDPsd0gVs500xeOewfySTsmEjf\u0026amp;index=10 ‚Äå\nFig. 2: Golden Gate Bridge, San Francisco, U.S.A (Image Source: Maarten van den Heuvel @ Unsplash). ","permalink":"https://mnguyen0226.github.io/posts/system_design_concepts/post/","summary":"[v.1.0] (01/20/2023): Post started!\nComputer Memory \u0026amp; Storage Storage HDD (hard disk drive): it works by spinning magnetics disk. SSD (solid state drive): it uses NAND-based flash memory, providing fast data access, reduces power consumption, and increases durability. It is more expensive. USB Drive: is a small plug-and-play device for convenient data transfer between computers. SD Card is commonly found in camera and smartphone. There is SD Card, Mini Card, and Micro Card.","title":"System Design Fundamentals Mega-Blog"},{"content":"[v.1.0] (10/2/2023): Post started (On-going)!\nLinked Lists In the previous post, we learnt that List can be implemented in ArrayLists or LinkedLists and they both behave in the same way. So why choose one over the other?\nAlthough the functional behaviours of ArrayLists and LinkedLists are the same, their performance behaviours are different. If we need to access or update a value, ArrayLists is a to-go choice, but if we anticipate to insert or delete value in the middle of the array, we should choose LinkedLists.\nFig. 1: LinkedList vs ArrayList. Let\u0026rsquo;s look at the example of List implemented using ArrayList\n/** * A dynamic array implementation of the List interface. * * @param \u0026lt;E\u0026gt; the type of elements in this list */ public class ArrayList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt; { private E[] elements; private int size; private int capacity; /** * Constructs an empty list with an initial capacity of ten. */ public ArrayList(){ size = 0; capacity = 10; elements = (E[]) new Object[capacity]; } /** * Appends the specified element to the end of this list. * * @param e element to be appended to this list */ public void add(E e){ if(size == capacity){ ensureCapacity(); } elements[size++] = e; } /** * Returns the element at the specified position in this list. * * @param index index of the element to return * @return the element at the specified position * @throws IndexOutOfBoundsException if the index is out of range */ public E get(int index){ if(index \u0026lt; 0 || index \u0026gt;= size){ throw new IndexOutOfBoundsException(); } return elements[index]; } /** * Removes the element at the specified position in this list. * * @param index the index of the element to be removed * @return the element previously at the specified position * @throws IndexOutOfBoundsException if the index is out of range */ public E remove(int index){ if(index \u0026lt; 0 || index \u0026gt;= size){ throw new IndexOutOfBoundsException(); } E removedElement = elements[index]; for(int i=index; i\u0026lt;size-1; i++){ elements[i] = elements[i+1]; } size--; return removedElement; } /** * Returns the number of elements in this list. * * @return the number of elements in this list */ public int size(){ return size; } /** * Increases the capacity of the array if necessary to ensure that it can hold at least the number of elements specified by the minimum capacity argument. */ private void ensureCapacity(){ int newCapacity = capacity * 2; E[] newElements = (E[]) new Object[newCapacity]; for(int i=0; i\u0026lt;size; i++){ newElements[i] = elements[i]; } elements = newElements; capacity = newCapacity; } } Let\u0026rsquo;s look at the example of List implemented using LinkedList\n/** * A doubly-linked list implementation. * * @param \u0026lt;E\u0026gt; the type of elements in this list */ public class LinkedList\u0026lt;E\u0026gt;{ private static class Node\u0026lt;E\u0026gt; { E element; Node\u0026lt;E\u0026gt; next; Node\u0026lt;E\u0026gt; previous; Node(E element, Node\u0026lt;E\u0026gt; next, Node\u0026lt;E\u0026gt; previous){ this.element = element; this.next = next; this.previous = previous; } } private Node\u0026lt;E\u0026gt; header; private int size = 0; /** * Constructs an empty list. */ public LinkedList(){ header = new Node\u0026lt;E\u0026gt;(null, null, null); header.next = header; header.previous = header; } /** * Appends the specified element to the end of this list. * * @param e element to be appended to this list */ public void add(E e){ Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(e, header, header.previous); header.previous.next = newNode; header.previous = newNode; size++; } /** * Returns the element at the specified position in this list. * * @param index index of the element to return * @return the element at the specified position * @throws IndexOutOfBoundsException if the index is out of range */ public E get(int index){ if(index \u0026lt; 0 || index \u0026gt;= size){ throw new IndexOutOfBoundsException(); } Node\u0026lt;E\u0026gt; current = header.next; for(int i=0; i\u0026lt;index; i++){ current = current.next; } return current.element; } /** * Removes the element at the specified position in this list. * * @param index the index of the element to be removed * @return the element previously at the specified position * @throws IndexOutOfBoundsException if the index is out of range */ public E remove(int index){ if(index \u0026lt; 0 || index \u0026gt;= size){ throw new IndexOutOfBoundsException(); } Node\u0026lt;E\u0026gt; current = header.next; for(int i=0; i\u0026lt;index; i++){ current = current.next; } current.previous.next = current.next; current.next.previous = current.previous; size--; return current.element; } /** * Returns the number of elements in this list. * * @return the number of elements in this list */ public int size(){ return size; } } Citation Cited as:\nNguyen, Minh. (October 2023). Java Fundamentals (Part 4) https://mnguyen0226.github.io/posts/java_fundamentals_4/post/ Or\n@article{nguyen2023java4, title = \u0026#34;Java Fundamentals (Part 4)\u0026#34;, author = \u0026#34;Nguyen, Minh\u0026#34;, journal = \u0026#34;mnguyen0226.github.io\u0026#34;, year = \u0026#34;2023\u0026#34;, month = \u0026#34;October\u0026#34;, url = \u0026#34;https://mnguyen0226.github.io/posts/java_fundamentals_4/post/\u0026#34; } References [1] P. Deitel, Java: How To Program, Early Objects: Pearson, 2017\n[2] Horstmann, Cay S. Big Java: Early Objects. John Wiley \u0026amp; Sons, 2020.\nFig. 2: Pinnacle Mountain State Park, Big Rock Township, Arkansas, U.S.A (Image Source: Joshua J. Cotten @ Unsplash). ","permalink":"https://mnguyen0226.github.io/posts/java_fundamentals_4/post/","summary":"[v.1.0] (10/2/2023): Post started (On-going)!\nLinked Lists In the previous post, we learnt that List can be implemented in ArrayLists or LinkedLists and they both behave in the same way. So why choose one over the other?\nAlthough the functional behaviours of ArrayLists and LinkedLists are the same, their performance behaviours are different. If we need to access or update a value, ArrayLists is a to-go choice, but if we anticipate to insert or delete value in the middle of the array, we should choose LinkedLists.","title":"Java Fundamentals (Part 4)"},{"content":"[v.1.0] (09/25/2023): Post published!\nTest-Driven Development Types Of Tests In software development, there are different ways to test softwares:\nBeta testing: Provides a finished or near-finished application to a group of users and sees what problems they come up with. Performance testing: Uses profiling tools to measure if we are getting acceptable response time. Is this application running as fast as it should be or it need to be? Stress testing: A type of performance testing. We want to know how well the application runs under heavy loads. Integration testing: Test one app\u0026rsquo;s integration-ability to another app. Unit Testing: Tests individual components to ensure they work as intended. Functional Testing: Confirms the application operates according to specifications and requirements. System Testing: Tests a fully integrated system for adherence to specified requirements. Regression Testing: Verifies that recent changes don\u0026rsquo;t adversely affect existing functionalities. Acceptance Testing: Determines if the software meets specified requirements. User Acceptance Testing (UAT) is a focused subset where end-users assess real-world application scenarios. Security Testing: Evaluates the software\u0026rsquo;s defense against threats, pinpointing potential vulnerabilities. Compatibility Testing: Checks if the software functions across different devices, browsers, and operating systems. Usability Testing: Assesses the software\u0026rsquo;s user-friendliness and gathers user feedback. Exploratory Testing: Unscheduled testing where testers actively explore and concurrently design and conduct tests. Smoke Testing: Initial testing to detect major failures and ascertain the software\u0026rsquo;s stability for more detailed testing. Sanity Testing: Examines specific functions affected by recent changes, a kind of focused regression testing. Monkey Testing: Random testing without knowledge of system internals, functionalities, or data. Alpha Testing: In-house testing done before releasing the software to a select external audience. etc\u0026hellip; Here, we focus on testing individual units of our code! We test our code as we write it, and we write code to automate the testing of our code.\nFig. 1: Paradox of (test) choices. Which tests to select to capture bugs? TDD In A Nutshell TDD is about writing the test prior to writing the application logic.\nCounter-intuitive? Having the need to pass 1 test gives us clarity on what is needed to be done.\nSteps:\nWrite a test. Watch the test fail. Write application logic - as simple as possible. Pass the test. Refactor, removing duplication Fig. 2: Unit-test (Image Source: monkeyuser.com). Questions \u0026amp; Answers Question 1: \u0026ldquo;Does TDD work for everything?\u0026rdquo;\nNo. There are problems that having TDD by itself does not guarantee the code is perfect, such as problems related to multi-threading, security, or user interfaces. Unit-testing does not replace other testing methods. Question 2: \u0026ldquo;Am I supposed to write all my tests first?\u0026rdquo;\nNo. It\u0026rsquo;s an iterative process where you write the test, expect to fail, develop the method, then move on to write the next test. Unit Testing Frameworks There are some unit-testing frameworks, such as: JUnit (Java), NUnit (.NET), PyUnit (Python), CppUnit (C++) or OCUnit (Objective-C). Although there are different frameworks, they all have the same idea.\nJUnit For Unit Testing \u0026amp; Test-Driven Development Unit tests are ultimately the best way to capture class-level and method-level requirements. Once the tests match the requirements, code can be developed to pass the tests. Unit tests aren\u0026rsquo;t the only kinds of tests; many other kinds are generally required as well\nJUnit is by far the most common way to formally write unit tests for Java code. There are many advantages to the formal approach of JUnit:\nFully integrated into all major Java IDEs to create and run tests without external tools. A robust library supports easily writing tests, to encourage quantity and quality of tests. Tests can be run ‚Äì and evaluated ‚Äì automatically. Coverage can be tracked, to ensure that every line of source code has been tested. Let\u0026rsquo;s look at the example. Note that the test is written prior to the code.\nimport org.junit.jupiter.api.Test; import static org.junit.jupiter.api.Assertions.assertEquals; public class CalculatorTest { @Test public void testAddition() { Calculator calculator = new Calculator(); int result = calculator.add(5, 3); assertEquals(8, result); } } public class Calculator { public int add(int a, int b) { return a + b; } } JUnit provides several assertion methods to make it easy to specify expected behavior.\nQuestions \u0026amp; Answers Question 1: \u0026ldquo;Do I test getters and setters?\u0026rdquo;\nDepends. Test only if they could meaningfully break. Question 2: \u0026ldquo;Do I test private methods\u0026rdquo;\nGenerally, no. Typically, just make a test for a public method that proves the private method works. Question 3: \u0026ldquo;Can I combine multiple test classes?\u0026rdquo;\nYes, it is called \u0026ldquo;Test Suites\u0026rdquo;. Question 4: \u0026ldquo;How do I control the order of tests?\u0026rdquo;\nNo. Controlling order suggests dependencies - avoid at all costs. Unit tests are not intended to test the application - only the individual units of code, in isolation. Citation Cited as:\nNguyen, Minh. (September 2023). Java Fundamentals (Part 3) https://mnguyen0226.github.io/posts/java_fundamentals_3/post/ Or\n@article{nguyen2023java3, title = \u0026#34;Java Fundamentals (Part 3)\u0026#34;, author = \u0026#34;Nguyen, Minh\u0026#34;, journal = \u0026#34;mnguyen0226.github.io\u0026#34;, year = \u0026#34;2023\u0026#34;, month = \u0026#34;September\u0026#34;, url = \u0026#34;https://mnguyen0226.github.io/posts/java_fundamentals_3/post/\u0026#34; } References [1] P. Deitel, Java: How To Program, Early Objects: Pearson, 2017\n[2] Horstmann, Cay S. Big Java: Early Objects. John Wiley \u0026amp; Sons, 2020.\n[3] S. Allardice, Test-Driven Developement: LinkedIn Learning, 2013.\nFig. 3: Orange Beach, Alabama, U.S.A (Image Source: Steven Van Elk @ Unsplash). ","permalink":"https://mnguyen0226.github.io/posts/java_fundamentals_3/post/","summary":"[v.1.0] (09/25/2023): Post published!\nTest-Driven Development Types Of Tests In software development, there are different ways to test softwares:\nBeta testing: Provides a finished or near-finished application to a group of users and sees what problems they come up with. Performance testing: Uses profiling tools to measure if we are getting acceptable response time. Is this application running as fast as it should be or it need to be? Stress testing: A type of performance testing.","title":"Java Fundamentals (Part 3)"},{"content":"[v.1.0] (09/11/2023): Post published!\nStatic \u0026amp; Final Modifiers Static Members Static members Are shared among all objects of the class (and available without any objects)\nStatic Methods: Are stateless utility operations, intended to be used without any instances. For example, Math.abs(), Character.isDigit(), Double.parseDouble().\nStatic Fields: As a best practice, these are always decleared in conjection with final for storing constant. For example, Math.PI, Integer.MAX_VALUE, Integer.MIN_VALUE.However, some final values are not actually constant.\nFinal Members Final Methods: Are methods that cannot be inherited.\nFinal Fields: Are fields that are assiged a value exactly once. A static final field is only \u0026ldquo;constant\u0026rdquo; if its type is a primitive or an immutable class.\nArray vs. List Array Here are some of the properties of Array:\nProvides random access to elements. An array is an object. Once length is fixed it can\u0026rsquo;t be changed. Elements can be objects or primitives. Special syntax for access, length. Java arrays\u0026rsquo; lengths are immutable but their contents are mutable. Let\u0026rsquo;s look at an example of Array\nString[] arr = new String[10]; // null x 10 String[] arr = {\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;}; myMethod(new String[]{\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;}); Let\u0026rsquo;s look at an example of Array class\nString[] arr2 = Arrays.copyOf(arr, arr.length); String[] arr3 = Arrays.copyOf(arr, arr.length * 2); Arrays.fill(arr, \u0026#34;\u0026#34;); Arrays.sort(arr); Arrays.toString(arr); Arrays.equals(arr1, arr2); List Here are some properties of List:\nProvides random access to elements. A list is an object. Can add elements. Elements can only be objects. No special syntax List is an interface: this means that we can implement List via ArrayList or LinkedList. Let\u0026rsquo;s look at an example of List:\nList\u0026lt;String\u0026gt; s1 = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; s2 = new LinkedList\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; s3 = new Arrays.asList(\u0026#34;abc\u0026#34;, \u0026#34;def\u0026#34;); # not recommend as you cannot add or remove element, you can update values though. s1.add(\u0026#34;abc\u0026#34;); s1.add(\u0026#34;abc\u0026#34;, 4); s1.size(); String str = s1.get(4); String str = s2.remove(4); Interface vs. Implementation Interface: Gives you everything you need to know to use the component (or answering the question \u0026ldquo;What does the componenet do?\u0026rdquo;).\nLet\u0026rsquo;s look at an example of an interface:\npublic interface List\u0026lt;E\u0026gt; { /** * Appends the specified element * to the end of this list. * @param element element to be added */ public void add(E element); /** * Inserts the specified element * at the specified position * in this list. * @param index location to insert element * @param element element to be inserted */ public void add(int index, E element); /** * Removes all of the elements * from this list. */ public void clear(); /* Others functions for a complete List interface */ public boolean contains(E element); public boolean equals(List\u0026lt;E\u0026gt; that); public E get(int index); public int indexOf(E element); public boolean isEmpty(); public Iterator\u0026lt;E\u0026gt; iterator(); public E remove(int index); public int size(); } Implementation: The behind-the-scenes internal working of the component (or answering the question \u0026ldquo;How does the component do it?\u0026rdquo;).\nTo connect with the idea of List, a List interface can have multiple implementations.\nLet\u0026rsquo;s look at an example of an implements:\n/** * A simple generic implementation of an ArrayList. * * @param \u0026lt;E\u0026gt; the type of elements in this list */ public class ArrayList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt; { /** * The array buffer into which the elements of the ArrayList are stored. */ private E[] elements; /** * The current number of elements in the ArrayList. */ private int size; /** * The total capacity of the ArrayList. */ private int capacity; /** * Constructs an empty ArrayList with an initial capacity of ten. */ public ArrayList() { size = 0; capacity = 10; elements = (E[]) new Object[capacity]; } /** * Inserts the specified element at the specified position in this list. * Shifts the element currently at that position (if any) and any subsequent elements to the right. * * @param index index at which the specified element is to be inserted * @param element element to be inserted * @throws AssertionError if the element is null * @throws AssertionError if the index is out of range (index \u0026lt; 0 || index \u0026gt;= size) */ public void add(int index, E element) { assert element != null; assert 0 \u0026lt;= index \u0026amp;\u0026amp; index \u0026lt; size; if (size == capacity) { capacity *= 2; elements = Arrays.copyOf(elements, capacity); } for (int i = size; i \u0026gt; index; i--) { elements[i] = elements[i-1]; } elements[index] = element; size++; } } Citation Cited as:\nNguyen, Minh. (September 2023). Java Fundamentals (Part 2) https://mnguyen0226.github.io/posts/java_fundamentals_2/post/ Or\n@article{nguyen2023java2, title = \u0026#34;Java Fundamentals (Part 2)\u0026#34;, author = \u0026#34;Nguyen, Minh\u0026#34;, journal = \u0026#34;mnguyen0226.github.io\u0026#34;, year = \u0026#34;2023\u0026#34;, month = \u0026#34;September\u0026#34;, url = \u0026#34;https://mnguyen0226.github.io/posts/java_fundamentals_2/post/\u0026#34; } References [1] P. Deitel, Java: How To Program, Early Objects: Pearson, 2017\n[2] Horstmann, Cay S. Big Java: Early Objects. John Wiley \u0026amp; Sons, 2020.\nFig. 1: Birch Lake, Alaska, U.S.A (Image Source: Alain Bonnardeaux @ Unsplash). ","permalink":"https://mnguyen0226.github.io/posts/java_fundamentals_2/post/","summary":"[v.1.0] (09/11/2023): Post published!\nStatic \u0026amp; Final Modifiers Static Members Static members Are shared among all objects of the class (and available without any objects)\nStatic Methods: Are stateless utility operations, intended to be used without any instances. For example, Math.abs(), Character.isDigit(), Double.parseDouble().\nStatic Fields: As a best practice, these are always decleared in conjection with final for storing constant. For example, Math.PI, Integer.MAX_VALUE, Integer.MIN_VALUE.However, some final values are not actually constant.","title":"Java Fundamentals (Part 2)"},{"content":"[v.1.0] (08/11/2023): Post published!\nObject-Oriented Concepts Terminologies Method: Stores the program statements what perform the task.\nClass: A proggram unit to store the set of methods that perform the class\u0026rsquo;s tasks.\nObject: An instance of the class.\nReuse: Of existing classes when building new classes and programs saves time and effort. Also, it helps you build more reliable and effective systems, as the existing classes and components often have undergone extensive testing, debugging, and performance tuning.\nMethod call: Each message is implemented as a method call that tells a method of the object to perform its task.\nEncapsulate: Classes (and their objects) encapsulate their attributes and methods. Objects may communicate with one another, but they are normally not allowed to know how other objects are implemented (details can be hidden within the object themselves). The practice of \u0026ldquo;information hiding\u0026rdquo; is crucial to good software engineering.\nInheritance: The new class (i.e. subclass) starts with the characteristics of an existing class (i.e. superclass), possibly customizing them and adding unique characteristrics of its own.\nInterfaces: Collections of related methods that typically enable you to tell objects what to do, but not how to do it. Note, a class \u0026ldquo;implements\u0026rdquo; zero or more interfaces, each of which can have one or more methods.\nUnified Modeling Language (UML): The most widely used graphical scheme for modeling object-oriented systems.\nJava application: Is a computer program that executes when you use the java command to launch the Java Virtual Machine (JVM).\nJava Programming: Is simple, safe, platform independent, rich library, designed for internet. Here is the comparison between C/C++ vs Java programming.\nFig. 1: C/C++ vs Java programming. Downside to JVM: As you have something in between your bytecode and CPU, the application is slower and less efficient (the disadvantage is mostly not notificable)\nOperating Systems (OS) OS: Are software systems that make using computers more convenient for users, application developers, and systems administrators. They provide services that allow each application to execute safely, efficiently, and concurrently.\nKernel: Is the software that contains the core components of the operating system.\nJava Programming Types \u0026amp; Variables Type: Defines a set of valeus and the operations that can be carried out on those values. There are 2 types in Java\nPrimitive types: simple values. Examples: int, short, long, float, double, boolean, byte, char. Reference types: objects. Examples: String, Interger, Array, List, HashSet, Rectangle, FileReader,\u0026hellip; Variable: A name for a value that you want to use at a later time.\nClasses, Objects, \u0026amp; Methods Rectangle is a class in package java.awt. Let\u0026rsquo;s implement a simplified version in a package called simplified.geometry.\nEvery public class, field, constructor, and method should be documented with appropriate Javadoc comments and tags.\n/** * Represents a rectangle defined by a set of x, y coordinates and dimensions (width and height). * The class provides basic operations such as translation and resizing, and it also includes * methods for querying the rectangle\u0026#39;s position and dimensions. * * @author Minh Nguyen * @version 1.0 */ package simplified.geometry; public class Rectangle { /** The x-coordinate of the rectangle\u0026#39;s top-left corner. */ private int x; /** The y-coordinate of the rectangle\u0026#39;s top-left corner. */ private int y; /** The width of the rectangle. */ private int width; /** The height of the rectangle. */ private int height; /** * Creates a new rectangle with coordinates (0,0) and dimensions (0,0). */ public Rectangle() { this(0, 0, 0, 0); } /** * Creates a new rectangle with specified coordinates and dimensions. * * @param x The x-coordinate of the rectangle\u0026#39;s top-left corner. * @param y The y-coordinate of the rectangle\u0026#39;s top-left corner. * @param width The width of the rectangle. * @param height The height of the rectangle. */ public Rectangle(int x, int y, int width, int height){ this.x = x; this.y = y; this.width = width; this.height = height; } /** * Returns the x-coordinate of the rectangle\u0026#39;s top-left corner. * * @return The x-coordinate. */ public int getX(){ return x; } /** * Returns the y-coordinate of the rectangle\u0026#39;s top-left corner. * * @return The y-coordinate. */ public int getY(){ return y; } /** * Returns the width of the rectangle. * * @return The width. */ public int getWidth(){ return width; } /** * Returns the height of the rectangle. * * @return The height. */ public int getHeight(){ return height; } /** * Sets the size of the rectangle to the specified width and height. * * @param width The new width of the rectangle. * @param height The new height of the rectangle. */ public void setSize(int width, int height){ this.width = width; this.height = height; } /** * Translates the rectangle by the specified amount in the x and y directions. * * @param dx The amount to translate in the x-direction. * @param dy The amount to translate in the y-direction. */ public void translate(int dx, int dy){ this.x += dx; this.y += dy; } /** * Checks if this rectangle is equal to another rectangle. * * @param that The rectangle to compare with. * @return true if the two rectangles have the same coordinates and dimensions; false otherwise. */ public boolean equals(Rectangle that){ return ((this.x == that.x) \u0026amp;\u0026amp; (this.y == that.y) \u0026amp;\u0026amp; (this.width == that.width) \u0026amp;\u0026amp; (this.height == that.height)); } /** * Returns a string representation of the rectangle in the format: * \u0026#34;Rectangle[x=...,y=...,width=...,height=...]\u0026#34;. * * @return A string representation of the rectangle. */ @Override public String toString() { return \u0026#34;Rectangle[x=\u0026#34; + x + \u0026#34;,y=\u0026#34; + y + \u0026#34;,width=\u0026#34; + width + \u0026#34;,height=\u0026#34; + height + \u0026#34;]\u0026#34;; } } Design \u0026amp; Language Concepts Encapsulation: Direct access to internal state should always be prohibited (by declaring them as private).\nConstructor: Defines the initial values of the fields for a newly-created object.\nAccessors: return artifacts of the current state of the object.\nMutators: allows potential modification of the current state, and may return useful values.\nObject Life Cycle:\nObjects are constructed (via the new operator) as instances of a class. The constructor (a special method with no return type) is called to initialize the fields. The name of the constructor is the name of the class The new operator returns the address of the newly-created object. This address acts as a \u0026ldquo;reference\u0026rdquo; (a pointer, in other languages) to the object Objects can then be accessed and/or mutated by their public methods Method calls are always requests; we ask the object to do something on our behalf. Accessors ask objects to return current state information. Mutators ask objects to make changes (which may be refused or altered) The state fields, and internal operations of each method, are hidden from other objects. Ensures the implementation can change without ripple effects throughout the system Objects cannot be deleted explicitly, but they can become unreachable Unreachable: no in-scope variable, nor reachable object\u0026rsquo;s field, references the object Once unreachable, an object becomes immediately eligible for garbage collection. The system eventually reclaims the memory of any unreachable objects. Modern garbage collection is an extremely efficient automatic background service. Citation Cited as:\nNguyen, Minh. (August 2023). Java Fundamentals (Part 1) https://mnguyen0226.github.io/posts/java_fundamentals_1/post/ Or\n@article{nguyen2023java1, title = \u0026#34;Java Fundamentals (Part 1)\u0026#34;, author = \u0026#34;Nguyen, Minh\u0026#34;, journal = \u0026#34;mnguyen0226.github.io\u0026#34;, year = \u0026#34;2023\u0026#34;, month = \u0026#34;August\u0026#34;, url = \u0026#34;https://mnguyen0226.github.io/posts/java_fundamentals_1/post/\u0026#34; } References [1] P. Deitel, Java: How To Program, Early Objects: Pearson, 2017\n[2] Horstmann, Cay S. Big Java: Early Objects. John Wiley \u0026amp; Sons, 2020.\nFig. 2: Grand Canyon National Park, Arizona, U.S.A (Image Source: Jason Thompson @ Unsplash). ","permalink":"https://mnguyen0226.github.io/posts/java_fundamentals_1/post/","summary":"[v.1.0] (08/11/2023): Post published!\nObject-Oriented Concepts Terminologies Method: Stores the program statements what perform the task.\nClass: A proggram unit to store the set of methods that perform the class\u0026rsquo;s tasks.\nObject: An instance of the class.\nReuse: Of existing classes when building new classes and programs saves time and effort. Also, it helps you build more reliable and effective systems, as the existing classes and components often have undergone extensive testing, debugging, and performance tuning.","title":"Java Fundamentals (Part 1)"}]